{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12f9662f",
   "metadata": {
    "papermill": {
     "duration": 0.003546,
     "end_time": "2026-01-15T16:04:11.024756",
     "exception": false,
     "start_time": "2026-01-15T16:04:11.021210",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Task 3: BERT Inference (Kaggle)\n",
    "\n",
    "Attach these Kaggle inputs before running:\n",
    "- Dataset: `thesis-data-task3-test-gold-500`\n",
    "- Notebook Output: `task3-bert-training` (latest version)\n",
    "\n",
    "The notebook loads the trained model, runs QA-based span extraction across 500 test files, reports Exact Match/F1, shows sample predictions, and saves `task3_bert_predictions.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fce5868f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T16:04:11.031516Z",
     "iopub.status.busy": "2026-01-15T16:04:11.031153Z",
     "iopub.status.idle": "2026-01-15T16:04:33.983497Z",
     "shell.execute_reply": "2026-01-15T16:04:33.982211Z"
    },
    "papermill": {
     "duration": 22.958465,
     "end_time": "2026-01-15T16:04:33.985760",
     "exception": false,
     "start_time": "2026-01-15T16:04:11.027295",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Libraries imported\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Cell 1: Setup\n",
    "# ============================================================\n",
    "import json\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "print(\"âœ… Libraries imported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d43cf96",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T16:04:33.992978Z",
     "iopub.status.busy": "2026-01-15T16:04:33.992385Z",
     "iopub.status.idle": "2026-01-15T16:04:59.187444Z",
     "shell.execute_reply": "2026-01-15T16:04:59.186248Z"
    },
    "papermill": {
     "duration": 25.20128,
     "end_time": "2026-01-15T16:04:59.189645",
     "exception": false,
     "start_time": "2026-01-15T16:04:33.988365",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“¦ Loading model from: /kaggle/input/task3-bert-training/models/task3_bert_final\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-15 16:04:37.977438: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1768493078.302901      17 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1768493078.417045      17 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1768493079.200048      17 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1768493079.200122      17 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1768493079.200125      17 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1768493079.200128      17 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model loaded on cpu\n",
      "ðŸ“Š Model parameters: 108,893,186\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Cell 2: Load Model\n",
    "# ============================================================\n",
    "# Path to saved model from training notebook output\n",
    "model_path = '/kaggle/input/task3-bert-training/models/task3_bert_final'\n",
    "\n",
    "print(f\"ðŸ“¦ Loading model from: {model_path}\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_path)\n",
    "\n",
    "# Move to GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(f\"âœ… Model loaded on {device}\")\n",
    "print(f\"ðŸ“Š Model parameters: {model.num_parameters():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3aca2813",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T16:04:59.197589Z",
     "iopub.status.busy": "2026-01-15T16:04:59.196860Z",
     "iopub.status.idle": "2026-01-15T16:04:59.235138Z",
     "shell.execute_reply": "2026-01-15T16:04:59.233718Z"
    },
    "papermill": {
     "duration": 0.044974,
     "end_time": "2026-01-15T16:04:59.237706",
     "exception": false,
     "start_time": "2026-01-15T16:04:59.192732",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‚ Test path: /kaggle/input/thesis-data-task3-test-gold-500/test_gold_500\n",
      "ðŸ“Š Found 500 test files\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Cell 3: Load Test Data\n",
    "# ============================================================\n",
    "test_path = Path('/kaggle/input/thesis-data-task3-test-gold-500/test_gold_500')\n",
    "test_files = sorted(test_path.glob(\"*.in\"))\n",
    "\n",
    "print(f\"ðŸ“‚ Test path: {test_path}\")\n",
    "print(f\"ðŸ“Š Found {len(test_files)} test files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "604c5325",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T16:04:59.244890Z",
     "iopub.status.busy": "2026-01-15T16:04:59.244511Z",
     "iopub.status.idle": "2026-01-15T16:04:59.255904Z",
     "shell.execute_reply": "2026-01-15T16:04:59.254630Z"
    },
    "papermill": {
     "duration": 0.017722,
     "end_time": "2026-01-15T16:04:59.258139",
     "exception": false,
     "start_time": "2026-01-15T16:04:59.240417",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Inference function defined\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Cell 4: Inference Function\n",
    "# ============================================================\n",
    "def extract_citation_span(text, citation, model, tokenizer, device, max_length=512):\n",
    "    \"\"\"\n",
    "    Extract span for a given citation using Question Answering approach\n",
    "    \"\"\"\n",
    "    # Create question\n",
    "    question = f\"What does citation {citation} support?\"\n",
    "\n",
    "    # Tokenize\n",
    "    inputs = tokenizer(\n",
    "        question,\n",
    "        text,\n",
    "        max_length=max_length,\n",
    "        truncation='only_second',\n",
    "        return_tensors='pt',\n",
    "        padding=True\n",
    "    )\n",
    "\n",
    "    # Move to device\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "    # Get predictions\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    # Get start and end positions\n",
    "    start_logits = outputs.start_logits\n",
    "    end_logits = outputs.end_logits\n",
    "\n",
    "    start_idx = torch.argmax(start_logits, dim=1).item()\n",
    "    end_idx = torch.argmax(end_logits, dim=1).item()\n",
    "\n",
    "    # Decode answer\n",
    "    if start_idx <= end_idx and start_idx > 0:\n",
    "        answer_tokens = inputs['input_ids'][0][start_idx:end_idx+1]\n",
    "        predicted_span = tokenizer.decode(answer_tokens, skip_special_tokens=True)\n",
    "    else:\n",
    "        predicted_span = \"\"\n",
    "\n",
    "    # Get confidence scores\n",
    "    start_prob = torch.softmax(start_logits, dim=1)[0][start_idx].item()\n",
    "    end_prob = torch.softmax(end_logits, dim=1)[0][end_idx].item()\n",
    "    confidence = (start_prob + end_prob) / 2\n",
    "\n",
    "    return {\n",
    "        'predicted_span': predicted_span,\n",
    "        'start_idx': start_idx,\n",
    "        'end_idx': end_idx,\n",
    "        'confidence': confidence\n",
    "    }\n",
    "\n",
    "print(\"âœ… Inference function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b8652b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T16:04:59.266258Z",
     "iopub.status.busy": "2026-01-15T16:04:59.265855Z",
     "iopub.status.idle": "2026-01-15T16:15:38.739683Z",
     "shell.execute_reply": "2026-01-15T16:15:38.738694Z"
    },
    "papermill": {
     "duration": 639.480939,
     "end_time": "2026-01-15T16:15:38.741909",
     "exception": false,
     "start_time": "2026-01-15T16:04:59.260970",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Starting inference...\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [10:39<00:00,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Inference complete!\n",
      "ðŸ“Š Processed: 1272 predictions\n",
      "âŒ Errors: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Cell 5: Run Inference on Test Set\n",
    "# ============================================================\n",
    "results = []\n",
    "errors = []\n",
    "\n",
    "print(\"ðŸš€ Starting inference...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for test_file in tqdm(test_files, desc=\"Processing files\"):\n",
    "    try:\n",
    "        # Load input file\n",
    "        with open(test_file) as f:\n",
    "            in_data = json.load(f)\n",
    "\n",
    "        # Load label file (for comparison)\n",
    "        label_file = test_file.with_suffix('.label')\n",
    "        with open(label_file) as f:\n",
    "            label_data = json.load(f)\n",
    "\n",
    "        text = in_data['text']\n",
    "        citation_spans = label_data.get('citation_spans', [])\n",
    "\n",
    "        # Process each citation\n",
    "        for span_info in citation_spans:\n",
    "            citation_id = span_info['citation_id']\n",
    "            gold_span = span_info['span_text']\n",
    "\n",
    "            # Run inference\n",
    "            prediction = extract_citation_span(\n",
    "                text=text,\n",
    "                citation=citation_id,\n",
    "                model=model,\n",
    "                tokenizer=tokenizer,\n",
    "                device=device\n",
    "            )\n",
    "\n",
    "            results.append({\n",
    "                'file': test_file.stem,\n",
    "                'citation_id': citation_id,\n",
    "                'gold_span': gold_span,\n",
    "                'predicted_span': prediction['predicted_span'],\n",
    "                'confidence': prediction['confidence'],\n",
    "                'start_idx': prediction['start_idx'],\n",
    "                'end_idx': prediction['end_idx']\n",
    "            })\n",
    "\n",
    "    except Exception as e:\n",
    "        errors.append({\n",
    "            'file': test_file.stem,\n",
    "            'error': str(e)\n",
    "        })\n",
    "\n",
    "print(f\"âœ… Inference complete!\")\n",
    "print(f\"ðŸ“Š Processed: {len(results)} predictions\")\n",
    "print(f\"âŒ Errors: {len(errors)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c2f5266",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T16:15:38.794461Z",
     "iopub.status.busy": "2026-01-15T16:15:38.794054Z",
     "iopub.status.idle": "2026-01-15T16:15:38.826402Z",
     "shell.execute_reply": "2026-01-15T16:15:38.825180Z"
    },
    "papermill": {
     "duration": 0.059992,
     "end_time": "2026-01-15T16:15:38.828418",
     "exception": false,
     "start_time": "2026-01-15T16:15:38.768426",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ðŸ“Š EVALUATION METRICS\n",
      "============================================================\n",
      "Total predictions: 1272\n",
      "Exact Match: 0.0094 (12/1272)\n",
      "F1 Score: 0.2596\n",
      "Average Confidence: 0.6060\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Cell 6: Calculate Metrics\n",
    "# ============================================================\n",
    "def calculate_exact_match(gold, pred):\n",
    "    \"\"\"Exact match: predicted == gold (after normalization)\"\"\"\n",
    "    return gold.strip().lower() == pred.strip().lower()\n",
    "\n",
    "\n",
    "def calculate_f1(gold, pred):\n",
    "    \"\"\"F1 score based on token overlap\"\"\"\n",
    "    gold_tokens = gold.strip().lower().split()\n",
    "    pred_tokens = pred.strip().lower().split()\n",
    "\n",
    "    if len(gold_tokens) == 0 or len(pred_tokens) == 0:\n",
    "        return 0.0\n",
    "\n",
    "    common = set(gold_tokens) & set(pred_tokens)\n",
    "\n",
    "    if len(common) == 0:\n",
    "        return 0.0\n",
    "\n",
    "    precision = len(common) / len(pred_tokens)\n",
    "    recall = len(common) / len(gold_tokens)\n",
    "\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    return f1\n",
    "\n",
    "\n",
    "# Calculate metrics\n",
    "exact_matches = 0\n",
    "total_f1 = 0\n",
    "\n",
    "for result in results:\n",
    "    if calculate_exact_match(result['gold_span'], result['predicted_span']):\n",
    "        exact_matches += 1\n",
    "\n",
    "    total_f1 += calculate_f1(result['gold_span'], result['predicted_span'])\n",
    "\n",
    "exact_match_score = exact_matches / len(results) if results else 0\n",
    "avg_f1_score = total_f1 / len(results) if results else 0\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ðŸ“Š EVALUATION METRICS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Total predictions: {len(results)}\")\n",
    "print(f\"Exact Match: {exact_match_score:.4f} ({exact_matches}/{len(results)})\")\n",
    "print(f\"F1 Score: {avg_f1_score:.4f}\")\n",
    "print(f\"Average Confidence: {sum(r['confidence'] for r in results)/len(results):.4f}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e498a2ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T16:15:38.879015Z",
     "iopub.status.busy": "2026-01-15T16:15:38.878640Z",
     "iopub.status.idle": "2026-01-15T16:15:38.886267Z",
     "shell.execute_reply": "2026-01-15T16:15:38.885243Z"
    },
    "papermill": {
     "duration": 0.03557,
     "end_time": "2026-01-15T16:15:38.888257",
     "exception": false,
     "start_time": "2026-01-15T16:15:38.852687",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‹ SAMPLE PREDICTIONS:\n",
      "============================================================\n",
      "Example 1:\n",
      "File: 10050\n",
      "Citation: [CITATION_1]\n",
      "Gold Span: Studies of vertebrate hearts suggest a role for Kind2 in cardiac development and function, however t...\n",
      "Predicted: . when drosophila cardiomyocytes fail to couple together to form a cardiac syncytium, synchronous co...\n",
      "Confidence: 0.7373\n",
      "Result: âŒ NO MATCH\n",
      "============================================================\n",
      "Example 2:\n",
      "File: 10050\n",
      "Citation: [CITATION_2]\n",
      "Gold Span: Studies of vertebrate hearts suggest a role for Kind2 in cardiac development and function, however t...\n",
      "Predicted: . when drosophila cardiomyocytes fail to couple together to form a cardiac syncytium, synchronous co...\n",
      "Confidence: 0.7814\n",
      "Result: âŒ NO MATCH\n",
      "============================================================\n",
      "Example 3:\n",
      "File: 10198\n",
      "Citation: [CITATION_1]\n",
      "Gold Span: Some major breath VOCs have already been investigated in this form, e.g., during rest and exercise c...\n",
      "Predicted: ...\n",
      "Confidence: 0.5443\n",
      "Result: âŒ NO MATCH\n",
      "============================================================\n",
      "Example 4:\n",
      "File: 10198\n",
      "Citation: [CITATION_2]\n",
      "Gold Span: Some major breath VOCs have already been investigated in this form, e.g., during rest and exercise c...\n",
      "Predicted: . some major breath vocs have already been investigated in this form, e. g., during rest and exercis...\n",
      "Confidence: 0.5549\n",
      "Result: âŒ NO MATCH\n",
      "============================================================\n",
      "Example 5:\n",
      "File: 10198\n",
      "Citation: [CITATION_3]\n",
      "Gold Span: Some major breath VOCs have already been investigated in this form, e.g., during rest and exercise c...\n",
      "Predicted: ....\n",
      "Confidence: 0.5593\n",
      "Result: âŒ NO MATCH\n",
      "============================================================\n",
      "Example 6:\n",
      "File: 10198\n",
      "Citation: [CITATION_4]\n",
      "Gold Span: Some major breath VOCs have already been investigated in this form, e.g., during rest and exercise c...\n",
      "Predicted: . some major breath vocs have already been investigated in this form, e. g., during rest and exercis...\n",
      "Confidence: 0.6827\n",
      "Result: âŒ NO MATCH\n",
      "============================================================\n",
      "Example 7:\n",
      "File: 10198\n",
      "Citation: [CITATION_5]\n",
      "Gold Span: Some major breath VOCs have already been investigated in this form, e.g., during rest and exercise c...\n",
      "Predicted: . some major breath vocs have already been investigated in this form, e. g., during rest and exercis...\n",
      "Confidence: 0.5982\n",
      "Result: âŒ NO MATCH\n",
      "============================================================\n",
      "Example 8:\n",
      "File: 10198\n",
      "Citation: [CITATION_6]\n",
      "Gold Span: Some major breath VOCs have already been investigated in this form, e.g., during rest and exercise c...\n",
      "Predicted: . some major breath vocs have already been investigated in this form, e. g., during rest and exercis...\n",
      "Confidence: 0.6626\n",
      "Result: âŒ NO MATCH\n",
      "============================================================\n",
      "Example 9:\n",
      "File: 10198\n",
      "Citation: [CITATION_7]\n",
      "Gold Span: Some major breath VOCs have already been investigated in this form, e.g., during rest and exercise c...\n",
      "Predicted: . some major breath vocs have already been investigated in this form, e. g., during rest and exercis...\n",
      "Confidence: 0.5946\n",
      "Result: âŒ NO MATCH\n",
      "============================================================\n",
      "Example 10:\n",
      "File: 10198\n",
      "Citation: [CITATION_8]\n",
      "Gold Span: Some major breath VOCs have already been investigated in this form, e.g., during rest and exercise c...\n",
      "Predicted: ....\n",
      "Confidence: 0.6382\n",
      "Result: âŒ NO MATCH\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Cell 7: Show Examples\n",
    "# ============================================================\n",
    "print(\"ðŸ“‹ SAMPLE PREDICTIONS:\")\n",
    "\n",
    "# Show first 10 predictions\n",
    "for i, result in enumerate(results[:10]):\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Example {i+1}:\")\n",
    "    print(f\"File: {result['file']}\")\n",
    "    print(f\"Citation: {result['citation_id']}\")\n",
    "    print(f\"Gold Span: {result['gold_span'][:100]}...\")\n",
    "    print(f\"Predicted: {result['predicted_span'][:100]}...\")\n",
    "    print(f\"Confidence: {result['confidence']:.4f}\")\n",
    "    match = \"âœ… MATCH\" if calculate_exact_match(result['gold_span'], result['predicted_span']) else \"âŒ NO MATCH\"\n",
    "    print(f\"Result: {match}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a247eec9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T16:15:38.940358Z",
     "iopub.status.busy": "2026-01-15T16:15:38.939993Z",
     "iopub.status.idle": "2026-01-15T16:15:38.987252Z",
     "shell.execute_reply": "2026-01-15T16:15:38.985965Z"
    },
    "papermill": {
     "duration": 0.076829,
     "end_time": "2026-01-15T16:15:38.989553",
     "exception": false,
     "start_time": "2026-01-15T16:15:38.912724",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Results saved to: task3_bert_predictions.csv\n",
      "ðŸ“Š Total rows: 1272\n",
      "============================================================\n",
      "âœ… INFERENCE COMPLETE!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Cell 8: Save Results\n",
    "# ============================================================\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Save to CSV\n",
    "output_file = 'task3_bert_predictions.csv'\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"âœ… Results saved to: {output_file}\")\n",
    "print(f\"ðŸ“Š Total rows: {len(df)}\")\n",
    "\n",
    "# Show errors if any\n",
    "if errors:\n",
    "    print(f\"âš ï¸ Errors encountered: {len(errors)}\")\n",
    "    for error in errors[:5]:\n",
    "        print(f\"  - {error['file']}: {error['error']}\")\n",
    "\n",
    "print(\"\" + \"=\"*60)\n",
    "print(\"âœ… INFERENCE COMPLETE!\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 9262587,
     "sourceId": 14502360,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 291885313,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 31234,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 695.254013,
   "end_time": "2026-01-15T16:15:42.271571",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-01-15T16:04:07.017558",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
