{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe9e28fe",
   "metadata": {
    "papermill": {
     "duration": 0.003409,
     "end_time": "2026-01-18T09:26:27.463372",
     "exception": false,
     "start_time": "2026-01-18T09:26:27.459963",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Task 3: BERT Inference (Kaggle)\n",
    "\n",
    "Attach these Kaggle inputs before running:\n",
    "- Dataset: `thesis-data-task3-test-gold-500`\n",
    "- Notebook Output: `task3-bert-training` (latest version)\n",
    "\n",
    "The notebook loads the trained model, runs QA-based span extraction across 500 test files, reports Exact Match/F1, shows sample predictions, and saves `task3_bert_predictions.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afd6cc27",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-18T09:26:27.469917Z",
     "iopub.status.busy": "2026-01-18T09:26:27.469540Z",
     "iopub.status.idle": "2026-01-18T09:26:48.928603Z",
     "shell.execute_reply": "2026-01-18T09:26:48.927222Z"
    },
    "papermill": {
     "duration": 21.46485,
     "end_time": "2026-01-18T09:26:48.930637",
     "exception": false,
     "start_time": "2026-01-18T09:26:27.465787",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Libraries imported\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Cell 1: Setup\n",
    "# ============================================================\n",
    "import json\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "print(\"‚úÖ Libraries imported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ab5ed2e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-18T09:26:48.937688Z",
     "iopub.status.busy": "2026-01-18T09:26:48.936963Z",
     "iopub.status.idle": "2026-01-18T09:27:13.766940Z",
     "shell.execute_reply": "2026-01-18T09:27:13.765681Z"
    },
    "papermill": {
     "duration": 24.83582,
     "end_time": "2026-01-18T09:27:13.768925",
     "exception": false,
     "start_time": "2026-01-18T09:26:48.933105",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Loading model from: /kaggle/input/task3-bert-training/models/task3_bert_final\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-18 09:26:52.926353: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1768728413.249060      18 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1768728413.345280      18 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1768728414.143810      18 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1768728414.143860      18 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1768728414.143863      18 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1768728414.143865      18 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model loaded on cpu\n",
      "üìä Model parameters: 108,893,186\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Cell 2: Load Model\n",
    "# ============================================================\n",
    "# Path to saved model from training notebook output\n",
    "model_path = '/kaggle/input/task3-bert-training/models/task3_bert_final'\n",
    "\n",
    "print(f\"üì¶ Loading model from: {model_path}\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_path)\n",
    "\n",
    "# Move to GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(f\"‚úÖ Model loaded on {device}\")\n",
    "print(f\"üìä Model parameters: {model.num_parameters():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4f54f9f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-18T09:27:13.776868Z",
     "iopub.status.busy": "2026-01-18T09:27:13.775594Z",
     "iopub.status.idle": "2026-01-18T09:27:13.805628Z",
     "shell.execute_reply": "2026-01-18T09:27:13.804303Z"
    },
    "papermill": {
     "duration": 0.035846,
     "end_time": "2026-01-18T09:27:13.807539",
     "exception": false,
     "start_time": "2026-01-18T09:27:13.771693",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Test path: /kaggle/input/thesis-data-task3-test-gold-500/test_gold_500\n",
      "üìä Found 500 test files\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Cell 3: Load Test Data\n",
    "# ============================================================\n",
    "test_path = Path('/kaggle/input/thesis-data-task3-test-gold-500/test_gold_500')\n",
    "test_files = sorted(test_path.glob(\"*.in\"))\n",
    "\n",
    "print(f\"üìÇ Test path: {test_path}\")\n",
    "print(f\"üìä Found {len(test_files)} test files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "257b23a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-18T09:27:13.814902Z",
     "iopub.status.busy": "2026-01-18T09:27:13.814447Z",
     "iopub.status.idle": "2026-01-18T09:27:13.825291Z",
     "shell.execute_reply": "2026-01-18T09:27:13.823914Z"
    },
    "papermill": {
     "duration": 0.016883,
     "end_time": "2026-01-18T09:27:13.827168",
     "exception": false,
     "start_time": "2026-01-18T09:27:13.810285",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Inference function defined\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Cell 4: Inference Function\n",
    "# ============================================================\n",
    "def extract_citation_span(text, citation, model, tokenizer, device, max_length=512):\n",
    "    \"\"\"\n",
    "    Extract span for a given citation using Question Answering approach\n",
    "    \"\"\"\n",
    "    # Create question\n",
    "    question = f\"What does citation {citation} support?\"\n",
    "\n",
    "    # Tokenize\n",
    "    inputs = tokenizer(\n",
    "        question,\n",
    "        text,\n",
    "        max_length=max_length,\n",
    "        truncation='only_second',\n",
    "        return_tensors='pt',\n",
    "        padding=True\n",
    "    )\n",
    "\n",
    "    # Move to device\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "    # Get predictions\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    # Get start and end positions\n",
    "    start_logits = outputs.start_logits\n",
    "    end_logits = outputs.end_logits\n",
    "\n",
    "    start_idx = torch.argmax(start_logits, dim=1).item()\n",
    "    end_idx = torch.argmax(end_logits, dim=1).item()\n",
    "\n",
    "    # Decode answer\n",
    "    if start_idx <= end_idx and start_idx > 0:\n",
    "        answer_tokens = inputs['input_ids'][0][start_idx:end_idx+1]\n",
    "        predicted_span = tokenizer.decode(answer_tokens, skip_special_tokens=True)\n",
    "    else:\n",
    "        predicted_span = \"\"\n",
    "\n",
    "    # Get confidence scores\n",
    "    start_prob = torch.softmax(start_logits, dim=1)[0][start_idx].item()\n",
    "    end_prob = torch.softmax(end_logits, dim=1)[0][end_idx].item()\n",
    "    confidence = (start_prob + end_prob) / 2\n",
    "\n",
    "    return {\n",
    "        'predicted_span': predicted_span,\n",
    "        'start_idx': start_idx,\n",
    "        'end_idx': end_idx,\n",
    "        'confidence': confidence\n",
    "    }\n",
    "\n",
    "print(\"‚úÖ Inference function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18ee959d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-18T09:27:13.834838Z",
     "iopub.status.busy": "2026-01-18T09:27:13.834299Z",
     "iopub.status.idle": "2026-01-18T09:37:42.447100Z",
     "shell.execute_reply": "2026-01-18T09:37:42.446131Z"
    },
    "papermill": {
     "duration": 628.619943,
     "end_time": "2026-01-18T09:37:42.449882",
     "exception": false,
     "start_time": "2026-01-18T09:27:13.829939",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting inference...\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 500/500 [10:28<00:00,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Inference complete!\n",
      "üìä Processed: 1272 predictions\n",
      "‚ùå Errors: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Cell 5: Run Inference on Test Set\n",
    "# ============================================================\n",
    "results = []\n",
    "errors = []\n",
    "\n",
    "print(\"üöÄ Starting inference...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for test_file in tqdm(test_files, desc=\"Processing files\"):\n",
    "    try:\n",
    "        # Load input file\n",
    "        with open(test_file) as f:\n",
    "            in_data = json.load(f)\n",
    "\n",
    "        # Load label file (for comparison)\n",
    "        label_file = test_file.with_suffix('.label')\n",
    "        with open(label_file) as f:\n",
    "            label_data = json.load(f)\n",
    "\n",
    "        text = in_data['text']\n",
    "        citation_spans = label_data.get('citation_spans', [])\n",
    "\n",
    "        # Process each citation\n",
    "        for span_info in citation_spans:\n",
    "            citation_id = span_info['citation_id']\n",
    "            gold_span = span_info['span_text']\n",
    "\n",
    "            # Run inference\n",
    "            prediction = extract_citation_span(\n",
    "                text=text,\n",
    "                citation=citation_id,\n",
    "                model=model,\n",
    "                tokenizer=tokenizer,\n",
    "                device=device\n",
    "            )\n",
    "\n",
    "            results.append({\n",
    "                'file': test_file.stem,\n",
    "                'citation_id': citation_id,\n",
    "                'gold_span': gold_span,\n",
    "                'predicted_span': prediction['predicted_span'],\n",
    "                'confidence': prediction['confidence'],\n",
    "                'start_idx': prediction['start_idx'],\n",
    "                'end_idx': prediction['end_idx']\n",
    "            })\n",
    "\n",
    "    except Exception as e:\n",
    "        errors.append({\n",
    "            'file': test_file.stem,\n",
    "            'error': str(e)\n",
    "        })\n",
    "\n",
    "print(f\"‚úÖ Inference complete!\")\n",
    "print(f\"üìä Processed: {len(results)} predictions\")\n",
    "print(f\"‚ùå Errors: {len(errors)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b9da01b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-18T09:37:42.501497Z",
     "iopub.status.busy": "2026-01-18T09:37:42.501067Z",
     "iopub.status.idle": "2026-01-18T09:37:42.533397Z",
     "shell.execute_reply": "2026-01-18T09:37:42.532210Z"
    },
    "papermill": {
     "duration": 0.060302,
     "end_time": "2026-01-18T09:37:42.535263",
     "exception": false,
     "start_time": "2026-01-18T09:37:42.474961",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üìä EVALUATION METRICS\n",
      "============================================================\n",
      "Total predictions: 1272\n",
      "Exact Match: 0.0094 (12/1272)\n",
      "F1 Score: 0.2596\n",
      "Average Confidence: 0.6060\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Cell 6: Calculate Metrics\n",
    "# ============================================================\n",
    "def calculate_exact_match(gold, pred):\n",
    "    \"\"\"Exact match: predicted == gold (after normalization)\"\"\"\n",
    "    return gold.strip().lower() == pred.strip().lower()\n",
    "\n",
    "\n",
    "def calculate_f1(gold, pred):\n",
    "    \"\"\"F1 score based on token overlap\"\"\"\n",
    "    gold_tokens = gold.strip().lower().split()\n",
    "    pred_tokens = pred.strip().lower().split()\n",
    "\n",
    "    if len(gold_tokens) == 0 or len(pred_tokens) == 0:\n",
    "        return 0.0\n",
    "\n",
    "    common = set(gold_tokens) & set(pred_tokens)\n",
    "\n",
    "    if len(common) == 0:\n",
    "        return 0.0\n",
    "\n",
    "    precision = len(common) / len(pred_tokens)\n",
    "    recall = len(common) / len(gold_tokens)\n",
    "\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    return f1\n",
    "\n",
    "\n",
    "# Calculate metrics\n",
    "exact_matches = 0\n",
    "total_f1 = 0\n",
    "\n",
    "for result in results:\n",
    "    if calculate_exact_match(result['gold_span'], result['predicted_span']):\n",
    "        exact_matches += 1\n",
    "\n",
    "    total_f1 += calculate_f1(result['gold_span'], result['predicted_span'])\n",
    "\n",
    "exact_match_score = exact_matches / len(results) if results else 0\n",
    "avg_f1_score = total_f1 / len(results) if results else 0\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"üìä EVALUATION METRICS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Total predictions: {len(results)}\")\n",
    "print(f\"Exact Match: {exact_match_score:.4f} ({exact_matches}/{len(results)})\")\n",
    "print(f\"F1 Score: {avg_f1_score:.4f}\")\n",
    "print(f\"Average Confidence: {sum(r['confidence'] for r in results)/len(results):.4f}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e89ac416",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-18T09:37:42.591069Z",
     "iopub.status.busy": "2026-01-18T09:37:42.590178Z",
     "iopub.status.idle": "2026-01-18T09:37:42.617009Z",
     "shell.execute_reply": "2026-01-18T09:37:42.615985Z"
    },
    "papermill": {
     "duration": 0.058252,
     "end_time": "2026-01-18T09:37:42.620365",
     "exception": false,
     "start_time": "2026-01-18T09:37:42.562113",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== SAMPLE (TEXT -> GOLD -> PRED) =====\n",
      "\n",
      "==============================================================================================================\n",
      "[1] doc=10050  citation=[CITATION_1]  conf=0.7373\n",
      "\n",
      "TEXT:\n",
      "  c. Studies of vertebrate hearts suggest a role for Kind2 in cardiac development and function, however these studies\n",
      "  are limited by the embryonic lethality of Kind2 knock-out in the mouse model, and the lack of tissue specific Kind2\n",
      "  silencing in the fish model <<[CITATION_1]>> [CITATION_2] . The aberrant phenotype caused by silencing orthologs of\n",
      "  Kind2 in the cardiomyocytes of an invertebrate demonstrates that the protein's role in cardiac development has been\n",
      "  evolutionarily conserved and also reiterates the validity of using Droso\n",
      "\n",
      "GOLD:\n",
      "  Studies of vertebrate hearts suggest a role for Kind2 in cardiac development and function, however these studies are\n",
      "  limited by the embryonic lethality of Kind2 knock-out in the mouse model, and the lack of tissue specific Kind2\n",
      "  silencing in the fish model .\n",
      "\n",
      "PRED:\n",
      "  . when drosophila cardiomyocytes fail to couple together to form a cardiac syncytium, synchronous contractions and\n",
      "  fractional shortening of the adult heart are significantly reduced, despite individual cardiomyocytes remaining\n",
      "  myogenic. studies of vertebrate hearts suggest a role for kind2 in cardiac development and function, however these\n",
      "  studies are limited by the embryonic lethality of kind2 knock - out in the mouse model, and the lack of tissue\n",
      "  specific kind2 silencing in the fish model\n",
      "\n",
      "==============================================================================================================\n",
      "[2] doc=10050  citation=[CITATION_2]  conf=0.7814\n",
      "\n",
      "TEXT:\n",
      "  vertebrate hearts suggest a role for Kind2 in cardiac development and function, however these studies are limited by\n",
      "  the embryonic lethality of Kind2 knock-out in the mouse model, and the lack of tissue specific Kind2 silencing in the\n",
      "  fish model [CITATION_1] <<[CITATION_2]>> . The aberrant phenotype caused by silencing orthologs of Kind2 in the\n",
      "  cardiomyocytes of an invertebrate demonstrates that the protein's role in cardiac development has been evolutionarily\n",
      "  conserved and also reiterates the validity of using Drosophila to stud\n",
      "\n",
      "GOLD:\n",
      "  Studies of vertebrate hearts suggest a role for Kind2 in cardiac development and function, however these studies are\n",
      "  limited by the embryonic lethality of Kind2 knock-out in the mouse model, and the lack of tissue specific Kind2\n",
      "  silencing in the fish model .\n",
      "\n",
      "PRED:\n",
      "  . when drosophila cardiomyocytes fail to couple together to form a cardiac syncytium, synchronous contractions and\n",
      "  fractional shortening of the adult heart are significantly reduced, despite individual cardiomyocytes remaining\n",
      "  myogenic. studies of vertebrate hearts suggest a role for kind2 in cardiac development and function, however these\n",
      "  studies are limited by the embryonic lethality of kind2 knock - out in the mouse model, and the lack of tissue\n",
      "  specific kind2 silencing in the fish model\n",
      "\n",
      "==============================================================================================================\n",
      "[3] doc=10198  citation=[CITATION_1]  conf=0.5443\n",
      "\n",
      "TEXT:\n",
      "  quate physical models mapping substance-specific distribution mechanisms in the pulmonary tract as well as in the body\n",
      "  tissues. Some major breath VOCs have already been investigated in this form, e.g., during rest and exercise conditions\n",
      "  or exposure scenarios <<[CITATION_1]>> [CITATION_2] [CITATION_3] [CITATION_4] [CITATION_5] [CITATION_6] [CITATION_7]\n",
      "  [CITATION_8] [CITATION_9] . Such mechanistic descriptions of the observable exhalation kinetics give valuable insights\n",
      "  into the relevance of the measured breath concentrations with\n",
      "\n",
      "GOLD:\n",
      "  Some major breath VOCs have already been investigated in this form, e.g., during rest and exercise conditions or\n",
      "  exposure scenarios .\n",
      "\n",
      "PRED:\n",
      "  (empty)\n",
      "\n",
      "==============================================================================================================\n",
      "[4] doc=10198  citation=[CITATION_2]  conf=0.5549\n",
      "\n",
      "TEXT:\n",
      "  l models mapping substance-specific distribution mechanisms in the pulmonary tract as well as in the body tissues.\n",
      "  Some major breath VOCs have already been investigated in this form, e.g., during rest and exercise conditions or\n",
      "  exposure scenarios [CITATION_1] <<[CITATION_2]>> [CITATION_3] [CITATION_4] [CITATION_5] [CITATION_6] [CITATION_7]\n",
      "  [CITATION_8] [CITATION_9] . Such mechanistic descriptions of the observable exhalation kinetics give valuable insights\n",
      "  into the relevance of the measured breath concentrations with respect to th\n",
      "\n",
      "GOLD:\n",
      "  Some major breath VOCs have already been investigated in this form, e.g., during rest and exercise conditions or\n",
      "  exposure scenarios .\n",
      "\n",
      "PRED:\n",
      "  . some major breath vocs have already been investigated in this form, e. g., during rest and exercise conditions or\n",
      "  exposure scenarios [ citation _ 1 ] [ citation _ 2 ] [ citation _ 3 ] [ citation _ 4 ] [ citation _ 5 ] [ citation _ 6\n",
      "  ] [ citation _ 7 ] [ citation _ 8 ] [ citation _ 9 ].\n",
      "\n",
      "==============================================================================================================\n",
      "[5] doc=10198  citation=[CITATION_3]  conf=0.5593\n",
      "\n",
      "TEXT:\n",
      "  ing substance-specific distribution mechanisms in the pulmonary tract as well as in the body tissues. Some major\n",
      "  breath VOCs have already been investigated in this form, e.g., during rest and exercise conditions or exposure\n",
      "  scenarios [CITATION_1] [CITATION_2] <<[CITATION_3]>> [CITATION_4] [CITATION_5] [CITATION_6] [CITATION_7] [CITATION_8]\n",
      "  [CITATION_9] . Such mechanistic descriptions of the observable exhalation kinetics give valuable insights into the\n",
      "  relevance of the measured breath concentrations with respect to the endogenous\n",
      "\n",
      "GOLD:\n",
      "  Some major breath VOCs have already been investigated in this form, e.g., during rest and exercise conditions or\n",
      "  exposure scenarios .\n",
      "\n",
      "PRED:\n",
      "  .\n",
      "\n",
      "==============================================================================================================\n",
      "[6] doc=10198  citation=[CITATION_4]  conf=0.6827\n",
      "\n",
      "TEXT:\n",
      "  -specific distribution mechanisms in the pulmonary tract as well as in the body tissues. Some major breath VOCs have\n",
      "  already been investigated in this form, e.g., during rest and exercise conditions or exposure scenarios [CITATION_1]\n",
      "  [CITATION_2] [CITATION_3] <<[CITATION_4]>> [CITATION_5] [CITATION_6] [CITATION_7] [CITATION_8] [CITATION_9] . Such\n",
      "  mechanistic descriptions of the observable exhalation kinetics give valuable insights into the relevance of the\n",
      "  measured breath concentrations with respect to the endogenous situation and\n",
      "\n",
      "GOLD:\n",
      "  Some major breath VOCs have already been investigated in this form, e.g., during rest and exercise conditions or\n",
      "  exposure scenarios .\n",
      "\n",
      "PRED:\n",
      "  . some major breath vocs have already been investigated in this form, e. g., during rest and exercise conditions or\n",
      "  exposure scenarios [ citation _ 1 ] [ citation _ 2 ] [ citation _ 3 ] [ citation _ 4 ] [ citation _ 5 ] [ citation _ 6\n",
      "  ] [ citation _ 7 ] [ citation _ 8 ] [ citation _ 9 ].\n",
      "\n",
      "==============================================================================================================\n",
      "[7] doc=10198  citation=[CITATION_5]  conf=0.5982\n",
      "\n",
      "TEXT:\n",
      "  tribution mechanisms in the pulmonary tract as well as in the body tissues. Some major breath VOCs have already been\n",
      "  investigated in this form, e.g., during rest and exercise conditions or exposure scenarios [CITATION_1] [CITATION_2]\n",
      "  [CITATION_3] [CITATION_4] <<[CITATION_5]>> [CITATION_6] [CITATION_7] [CITATION_8] [CITATION_9] . Such mechanistic\n",
      "  descriptions of the observable exhalation kinetics give valuable insights into the relevance of the measured breath\n",
      "  concentrations with respect to the endogenous situation and hence are ma\n",
      "\n",
      "GOLD:\n",
      "  Some major breath VOCs have already been investigated in this form, e.g., during rest and exercise conditions or\n",
      "  exposure scenarios .\n",
      "\n",
      "PRED:\n",
      "  . some major breath vocs have already been investigated in this form, e. g., during rest and exercise conditions or\n",
      "  exposure scenarios [ citation _ 1 ] [ citation _ 2 ] [ citation _ 3 ] [ citation _ 4 ] [ citation _ 5 ] [ citation _ 6\n",
      "  ] [ citation _ 7 ] [ citation _ 8 ] [ citation _ 9 ].\n",
      "\n",
      "==============================================================================================================\n",
      "[8] doc=10198  citation=[CITATION_6]  conf=0.6626\n",
      "\n",
      "TEXT:\n",
      "  hanisms in the pulmonary tract as well as in the body tissues. Some major breath VOCs have already been investigated\n",
      "  in this form, e.g., during rest and exercise conditions or exposure scenarios [CITATION_1] [CITATION_2] [CITATION_3]\n",
      "  [CITATION_4] [CITATION_5] <<[CITATION_6]>> [CITATION_7] [CITATION_8] [CITATION_9] . Such mechanistic descriptions of\n",
      "  the observable exhalation kinetics give valuable insights into the relevance of the measured breath concentrations\n",
      "  with respect to the endogenous situation and hence are mandatory to fu\n",
      "\n",
      "GOLD:\n",
      "  Some major breath VOCs have already been investigated in this form, e.g., during rest and exercise conditions or\n",
      "  exposure scenarios .\n",
      "\n",
      "PRED:\n",
      "  . some major breath vocs have already been investigated in this form, e. g., during rest and exercise conditions or\n",
      "  exposure scenarios [ citation _ 1 ] [ citation _ 2 ] [ citation _ 3 ] [ citation _ 4 ] [ citation _ 5 ] [ citation _ 6\n",
      "  ] [ citation _ 7 ] [ citation _ 8 ] [ citation _ 9 ].\n",
      "\n",
      "==============================================================================================================\n",
      "[9] doc=10198  citation=[CITATION_7]  conf=0.5946\n",
      "\n",
      "TEXT:\n",
      "  e pulmonary tract as well as in the body tissues. Some major breath VOCs have already been investigated in this form,\n",
      "  e.g., during rest and exercise conditions or exposure scenarios [CITATION_1] [CITATION_2] [CITATION_3] [CITATION_4]\n",
      "  [CITATION_5] [CITATION_6] <<[CITATION_7]>> [CITATION_8] [CITATION_9] . Such mechanistic descriptions of the observable\n",
      "  exhalation kinetics give valuable insights into the relevance of the measured breath concentrations with respect to\n",
      "  the endogenous situation and hence are mandatory to fully exploit t\n",
      "\n",
      "GOLD:\n",
      "  Some major breath VOCs have already been investigated in this form, e.g., during rest and exercise conditions or\n",
      "  exposure scenarios .\n",
      "\n",
      "PRED:\n",
      "  . some major breath vocs have already been investigated in this form, e. g., during rest and exercise conditions or\n",
      "  exposure scenarios [ citation _ 1 ] [ citation _ 2 ] [ citation _ 3 ] [ citation _ 4 ] [ citation _ 5 ] [ citation _ 6\n",
      "  ] [ citation _ 7 ] [ citation _ 8 ] [ citation _ 9 ].\n",
      "\n",
      "==============================================================================================================\n",
      "[10] doc=10198  citation=[CITATION_8]  conf=0.6382\n",
      "\n",
      "TEXT:\n",
      "  ract as well as in the body tissues. Some major breath VOCs have already been investigated in this form, e.g., during\n",
      "  rest and exercise conditions or exposure scenarios [CITATION_1] [CITATION_2] [CITATION_3] [CITATION_4] [CITATION_5]\n",
      "  [CITATION_6] [CITATION_7] <<[CITATION_8]>> [CITATION_9] . Such mechanistic descriptions of the observable exhalation\n",
      "  kinetics give valuable insights into the relevance of the measured breath concentrations with respect to the\n",
      "  endogenous situation and hence are mandatory to fully exploit the diagnostic\n",
      "\n",
      "GOLD:\n",
      "  Some major breath VOCs have already been investigated in this form, e.g., during rest and exercise conditions or\n",
      "  exposure scenarios .\n",
      "\n",
      "PRED:\n",
      "  .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Cell 7: Show Examples (TEXT -> GOLD -> PRED)\n",
    "# ============================================================\n",
    "import json\n",
    "import textwrap\n",
    "from pathlib import Path\n",
    "\n",
    "TEST_DIR = Path(\"/kaggle/input/thesis-data-task3-test-gold-500/test_gold_500\")\n",
    "N = 10\n",
    "WIDTH = 120\n",
    "WINDOW = 260  # chars before/after citation marker\n",
    "\n",
    "def clean(s):\n",
    "    return \" \".join((s or \"\").split())\n",
    "\n",
    "def wrap(s, indent=\"  \"):\n",
    "    s = clean(s)\n",
    "    if not s:\n",
    "        return indent + \"(empty)\"\n",
    "    return textwrap.fill(s, width=WIDTH, initial_indent=indent, subsequent_indent=indent)\n",
    "\n",
    "def context(text, marker):\n",
    "    text = text or \"\"\n",
    "    idx = text.find(marker)\n",
    "    if idx == -1:\n",
    "        return f\"(marker {marker} not found)\"\n",
    "    start = max(0, idx - WINDOW)\n",
    "    end = min(len(text), idx + len(marker) + WINDOW)\n",
    "    snip = text[start:end].replace(marker, f\"<<{marker}>>\", 1)\n",
    "    return snip\n",
    "\n",
    "print(\"\\n===== SAMPLE (TEXT -> GOLD -> PRED) =====\\n\")\n",
    "\n",
    "for i, r in enumerate(results[:N], 1):\n",
    "    doc_id = r[\"file\"]\n",
    "    cid = r[\"citation_id\"]\n",
    "\n",
    "    label = json.load(open(TEST_DIR / f\"{doc_id}.label\"))\n",
    "    text = label.get(\"text\", \"\")\n",
    "    gold = next((x[\"span_text\"] for x in label.get(\"citation_spans\", []) if x[\"citation_id\"] == cid), \"\")\n",
    "    pred = r.get(\"predicted_span\", \"\")\n",
    "    conf = r.get(\"confidence\", 0.0)\n",
    "\n",
    "    print(\"=\" * 110)\n",
    "    print(f\"[{i}] doc={doc_id}  citation={cid}  conf={conf:.4f}\")\n",
    "\n",
    "    print(\"\\nTEXT:\")\n",
    "    print(wrap(context(text, cid), indent=\"  \"))\n",
    "\n",
    "    print(\"\\nGOLD:\")\n",
    "    print(wrap(gold, indent=\"  \"))\n",
    "\n",
    "    print(\"\\nPRED:\")\n",
    "    print(wrap(pred, indent=\"  \"))\n",
    "\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b846baa6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-18T09:37:42.673522Z",
     "iopub.status.busy": "2026-01-18T09:37:42.672917Z",
     "iopub.status.idle": "2026-01-18T09:37:42.727665Z",
     "shell.execute_reply": "2026-01-18T09:37:42.726313Z"
    },
    "papermill": {
     "duration": 0.083364,
     "end_time": "2026-01-18T09:37:42.729885",
     "exception": false,
     "start_time": "2026-01-18T09:37:42.646521",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Results saved to: task3_bert_predictions.csv\n",
      "üìä Total rows: 1272\n",
      "============================================================\n",
      "‚úÖ INFERENCE COMPLETE!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Cell 8: Save Results\n",
    "# ============================================================\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Save to CSV\n",
    "output_file = 'task3_bert_predictions.csv'\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"‚úÖ Results saved to: {output_file}\")\n",
    "print(f\"üìä Total rows: {len(df)}\")\n",
    "\n",
    "# Show errors if any\n",
    "if errors:\n",
    "    print(f\"‚ö†Ô∏è Errors encountered: {len(errors)}\")\n",
    "    for error in errors[:5]:\n",
    "        print(f\"  - {error['file']}: {error['error']}\")\n",
    "\n",
    "print(\"\" + \"=\"*60)\n",
    "print(\"‚úÖ INFERENCE COMPLETE!\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 9262587,
     "sourceId": 14502360,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 291885313,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 31234,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 682.36394,
   "end_time": "2026-01-18T09:37:45.792485",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-01-18T09:26:23.428545",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
