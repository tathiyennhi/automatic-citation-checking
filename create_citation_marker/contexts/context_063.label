Thus, the names of many Indian funders are very similar to the entities which usually fall into the UNI category, e.g., the Department of Science and Technology or the Department of Biotechnology. This pattern is more common to the entities which fall into the UNI category. Therefore, that might make the exact extraction of UNI and FUND entities more confusing. Moreover, many Indian Universities contain the name of individuals, e.g., Rajiv Gandhi University, which can cause confusion of the UNI category with the IND category. Generally, no improvement in increasing the size of the corpus for the FUND category can be explained by the ambiguous nature of the entities which fall into the FUND category and their semantical proximity with other types of entities. Analysis of the extracted entities showed that many entities were extracted correctly, but were assigned to the wrong category [CITATION_1]. Therefore, an additional classification algorithm applied to extracted entities could improve the model’s performance. 15 These differences in entity distribution are caused by the peculiarities of acknowledgement information stored in WoS. As only acknowledgements with indexed funding information are stored in the database, it was difficult to find an adequate number of acknowledged entities of other types 1 3 Scientometrics Conclusion In this paper, we evaluated different embedding models for the task of automatic extraction and classification of acknowledged entities from acknowledgment texts16. The annotation of the training corpora was the most challenging and time-consuming task of all data preparation procedures. Therefore, a semi-automated approach was used to help significantly accelerate the procedure. The study’s main limitations were its small size and just one annotator of the training corpora.