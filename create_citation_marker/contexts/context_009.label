Furthermore, large bibliographic databases such as Web of Science (WoS)1 and Scopus selectively index only funding information, i.e., names of funding organizations and grant identification numbers. Consequently, we want to extend that to other types of acknowledged entities: individuals, universities, corporations, and other miscellaneous information. Analysis of the acknowledged individuals provides insight into informal scientific collaboration [CITATION_1][CITATION_2]. Acknowledged universities and corporations reveal interactions and knowledge exchange between industry and universities [CITATION_3]. Entities from the miscellaneous category include other information like project names, which could uncover international scientific collaborations. The state-of-the-art named entity recognition (NER) models showed a great performance on the CoNLL-2003 dataset [CITATION_4][CITATION_5][CITATION_6][CITATION_7]. CoNLL-2003 corpus [CITATION_8] is a benchmark dataset for language-independent named entity recognition, i.e., designed to train and evaluate NER models. English data for the corpus were taken from the Reuters corpus. The dataset comprises four types of named entities: person, location, organisation, and miscellaneous. However, specific domains require specifically labelled training data. The development of a training dataset for the specific domain is an expensive and time-consuming process since NER usually requires a quite large training corpus.