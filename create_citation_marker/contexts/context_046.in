The entities in the miscellaneous category could provide useful information, but cannot be ascribed to other categories, e.g., names of projects and names of conferences. Figure 1 demonstrates an example of acknowledged entities of different types. To the best of our knowledge, Giles and Councill’s classification is the only existing classification of acknowledged entities and therefore can be applied to the NER task. Other works on acknowledgment analysis were focused on the classification of acknowledgment texts. The Flair NLP framework Flair is an open-sourced NLP framework built on PyTorch (Paszke et al., 2019), which is an open-source machine learning library. “The core idea of the framework is to present a simple, unified interface for conceptually very different types of word and document embeddings” (Akbik et al., 2019, p. 54). Flair has three default training algorithms for NER which were used for the first experiment in the present research: a) NER Model with Flair Embeddings (later on Flair Embeddings) (Akbik et al., 2018), b) NER Model with Transformers (later on Transformers) (Schweter & Akbik, 2020), and c) Zero-shot NER with TARS (later on TARS) (Halder et al., 2020) 8. The Flair Embeddings model uses stacked embeddings, i.e., a combination of contextual string embeddings (Akbik et al., 2018) with a static embeddings model. This approach will generate different embeddings for the same word depending on its context. Stacked embedding is an important Flair feature, as a combination of different embeddings might bring better results than their separate uses (Akbik et al., 2019). The Transformers model or FLERT-extension (document-level features for NER) is a set of settings to perform a NER on the document level using fine-tuning and feature-based 8 New transformer models as SciBERT or SsciBERT were not evaluated in this study, as the objective of the study is to evaluate the performance of the Flair default models. 1 3 Scientometrics Table 2 Number of sentences/texts in the training corpora Corpus No. Training set (train) Test set (test) Validation set (dev) Total 1 29/27 10/10 10/10 49/47 2 339/282 165/150 150/136 654/441 3 784/657 165/150 150/136 1099/816 4 1148/885 165/150 150/136 1463/1044 Table 3 Number of sentences/texts from each scientific domain in the training corpora Corpus No.