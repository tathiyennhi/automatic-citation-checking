[
  {
    "id": "doc_032_sent_01",
    "with_marker": "Flair has three default training algorithms for \nNER which were used for the first experiment in the present research: a) NER Model with \nFlair Embeddings (later on Flair Embeddings) [CITATION_35], b) NER Model with \nTransformers (later on Transformers) [CITATION_36], and c) Zero-shot NER \nwith TARS (later on TARS) [CITATION_37] 8.",
    "citations": [
      {
        "marker": "[CITATION_35]",
        "original": "Akbik et al., 2018"
      },
      {
        "marker": "[CITATION_36]",
        "original": "Schweter & Akbik, 2020"
      },
      {
        "marker": "[CITATION_37]",
        "original": "Halder et al., 2020"
      }
    ]
  },
  {
    "id": "doc_032_sent_02",
    "with_marker": "The Flair Embeddings model uses stacked embeddings, i.e., a combination of contex-\ntual string embeddings [CITATION_38] with a static embeddings model.",
    "citations": [
      {
        "marker": "[CITATION_38]",
        "original": "Akbik et al., 2018"
      }
    ]
  },
  {
    "id": "doc_032_sent_03",
    "with_marker": "This approach \nwill generate different embeddings for the same word depending on its context.",
    "citations": []
  },
  {
    "id": "doc_032_sent_04",
    "with_marker": "Stacked \nembedding is an important Flair feature, as a combination of different embeddings might \nbring better results than their separate uses [CITATION_39].",
    "citations": [
      {
        "marker": "[CITATION_39]",
        "original": "Akbik et al., 2019"
      }
    ]
  },
  {
    "id": "doc_032_sent_05",
    "with_marker": "The Transformers model or FLERT-extension (document-level features for NER) is a \nset of settings to perform a NER on the document level using fine-tuning and feature-based \nFig.",
    "citations": []
  }
]