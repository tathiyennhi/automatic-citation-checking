[
    {
        "original_sentence": "We trained and implemented a named entity recogni- tion (NER) task using the flair NLP framework",
        "citations": [
            {
                "citation_content": "NER"
            }
        ]
    },
    {
        "original_sentence": "Scientometrics 1 3 Introduction Acknowledgments in scientific papers are short texts where the author(s) “identify those  who made special intellectual or technical contribution to a study that are not sufficient  to qualify them for authorship” (Kassirer & Angell, 1991, p. 1511)",
        "citations": [
            {
                "citation_content": "Kassirer & Angell, 1991, p. 1511"
            }
        ]
    },
    {
        "original_sentence": "Cronin and Weaver  (1995) ascribe an acknowledgment alongside authorship and citedness to measures of a  researcher’s scholarly performance: a feature that reflects the researcher’s productivity and  impact",
        "citations": [
            {
                "citation_content": "1995"
            }
        ]
    },
    {
        "original_sentence": "Giles and Councill (2004) argue that acknowledgments to individuals, in the same  way as citations, may be used as a metric to measure an individual’s intellectual contribu- tion to scientific work",
        "citations": [
            {
                "citation_content": "2004"
            }
        ]
    },
    {
        "original_sentence": "Acknowledgments of  technical and instrumental support may reveal “indirect contributions of research labora- tories and universities to research activities” (Giles & Councill, 2004, p. 17599)",
        "citations": [
            {
                "citation_content": "Giles & Councill, 2004, p. 17599"
            }
        ]
    },
    {
        "original_sentence": "The analysis of acknowledgments is particularly interesting as acknowledgments may  give an insight into aspects of the scientific community, such as reward systems (Dzieżyc  & Kazienko, 2022), collaboration patterns, and hidden research trends (Giles & Councill,  2004; Diaz-Faes & Bordons, 2017)",
        "citations": [
            {
                "citation_content": "Dzieżyc  & Kazienko, 2022"
            },
            {
                "citation_content": "Giles & Councill,  2004; Diaz-Faes & Bordons, 2017"
            }
        ]
    },
    {
        "original_sentence": "To our knowledge, previous works on automatic acknowledgment analysis were mostly  concerned with the extraction of funding organizations and grant numbers (Alexandera &  Vries, 2021; Kayal et  al., 2017; Borst et  al., 2022) or classification of acknowledgment  texts (Song et al., 2020; Hubbard et al., 2022)",
        "citations": [
            {
                "citation_content": "Alexandera &  Vries, 2021; Kayal et  al., 2017; Borst et  al., 2022"
            },
            {
                "citation_content": "Song et al., 2020; Hubbard et al., 2022"
            }
        ]
    },
    {
        "original_sentence": "Analysis of the acknowledged individuals  provides insight into informal scientific collaboration (Rose & Georg, 2021; Kusumegi &  Sano, 2022)",
        "citations": [
            {
                "citation_content": "Rose & Georg, 2021; Kusumegi &  Sano, 2022"
            }
        ]
    },
    {
        "original_sentence": "Acknowledged universities and corporations reveal interactions and knowl- edge exchange between industry and universities (Chen et  al., 2022)",
        "citations": [
            {
                "citation_content": "Chen et  al., 2022"
            }
        ]
    },
    {
        "original_sentence": "The state-of-the-art named entity recognition (NER) models showed a great perfor - mance on the CoNLL-2003 dataset (Akbik et al., 2018; Devlin et al., 2018; Yamada et al.,  2020; Yu et  al., 2020)",
        "citations": [
            {
                "citation_content": "NER"
            },
            {
                "citation_content": "Akbik et al., 2018; Devlin et al., 2018; Yamada et al.,  2020; Yu et  al., 2020"
            }
        ]
    },
    {
        "original_sentence": "CoNLL-2003 corpus (Sang et  al., 2003) is a benchmark dataset  for language-independent named entity recognition, i.e., designed to train and evaluate  NER models",
        "citations": [
            {
                "citation_content": "Sang et  al., 2003"
            }
        ]
    },
    {
        "original_sentence": "Therefore, the objective of this paper is  to evaluate the performance of existing embedding models for the task of automatic extrac- tion and classification of acknowledged entities from the acknowledgment text in scientific  papers using small training datasets or without training data (zero-short approach)",
        "citations": [
            {
                "citation_content": "zero-short approach"
            }
        ]
    },
    {
        "original_sentence": "Scientometrics  1 3 The present paper is an extended version of the article (Smirnova & Mayr, 2022)2 pre- sented at the 3rd Workshop on Extraction and Evaluation of Knowledge Entities from Sci- entific Documents (EEKE2022).3 Flair, an open-source natural language processing (NLP)  framework (Akbik et al., 2019) is used in our study to create a tool for the extraction of  acknowledged entities because this library is easily customizable",
        "citations": [
            {
                "citation_content": "Smirnova & Mayr, 2022)2 pre- sented at the 3rd Workshop on Extraction and Evaluation of Knowledge Entities from Sci- entific Documents (EEKE2022).3 Flair, an open-source natural language processing (NLP"
            },
            {
                "citation_content": "EEKE2022).3 Flair, an open-source natural language processing (NLP"
            },
            {
                "citation_content": "NLP"
            },
            {
                "citation_content": "Akbik et al., 2019"
            }
        ]
    },
    {
        "original_sentence": "It offers the possibility  of creating a customized Named Entity Recognition (NER) tagger, which can be used for  processing and analyzing acknowledgment texts",
        "citations": [
            {
                "citation_content": "NER"
            }
        ]
    },
    {
        "original_sentence": "Furthermore, Flair has shown better accu- racy for NER tasks using pre-trained datasets in comparison with many other open source  NLP tools.4 In the first experiment (Sect.  4.1) we trained and implemented a NER task using three  default Flair NER models with two differently-sized corpora.5 All the descriptions of the  Flair framework features refer to the releases 0.9 and 0.11",
        "citations": [
            {
                "citation_content": "Sect.  4.1"
            }
        ]
    },
    {
        "original_sentence": "In Experiments 2 and 3 we  performed additional training with altered training parameters or altered training corpora  (Sects  4.2 and 4.3)",
        "citations": [
            {
                "citation_content": "Sects  4.2 and 4.3"
            }
        ]
    },
    {
        "original_sentence": "Most of the previous works on acknowledgment analysis were limited  by the manual evaluation of data and therefore by the amount of processed data (Giles  & Councill, 2004; Paul-Hus et al., 2017; Paul-Hus & Desrochers, 2019; Mccain, 2017)",
        "citations": [
            {
                "citation_content": "Giles  & Councill, 2004; Paul-Hus et al., 2017; Paul-Hus & Desrochers, 2019; Mccain, 2017"
            }
        ]
    },
    {
        "original_sentence": " Furthermore, Thomer and Weber (2014) argues that using named entities can benefit the  process of manual document classification and evaluation of the data",
        "citations": [
            {
                "citation_content": "2014"
            }
        ]
    },
    {
        "original_sentence": "That is why  2 In this paper we conducted an additional experiment (Experiment 3) with 2 new corpora (corpus Nos",
        "citations": [
            {
                "citation_content": "Experiment 3"
            }
        ]
    },
    {
        "original_sentence": " The first typology of acknowledgments was proposed by Mackintosh (1972) (as cited  in Cronin, 1995) and comprised three categories: facilities, access to data, and help of indi- viduals",
        "citations": [
            {
                "citation_content": "1972"
            },
            {
                "citation_content": "as cited  in Cronin, 1995"
            }
        ]
    },
    {
        "original_sentence": "McCain (1991) distinguished five types of acknowledgements: research-related  information, secondary access to research-related information, specific research-related  communication, general peer communication, and technical or clerical support",
        "citations": [
            {
                "citation_content": "1991"
            }
        ]
    },
    {
        "original_sentence": "Cronin and  Weaver (1995) defined three broad categories: resource-, procedure- and concept-related",
        "citations": [
            {
                "citation_content": "1995"
            }
        ]
    },
    {
        "original_sentence": " Mejia and Kajikawa (2018) developed a four-level classification based on sponsored  research field: change maker, incremental, breakthrough, and matured",
        "citations": [
            {
                "citation_content": "2018"
            }
        ]
    },
    {
        "original_sentence": "Doehne and Herfeld (2023) distinguished acknowledgements from the perspective of  appreciation of influential scholars and defined two axes: scientific influence and insti- tutional influence",
        "citations": [
            {
                "citation_content": "2023"
            }
        ]
    },
    {
        "original_sentence": "Wang and Shapira (2011) investigated the connection between research funding and  the development of science and technology using acknowledgments from articles from the  field of nanotechnology",
        "citations": [
            {
                "citation_content": "2011"
            }
        ]
    },
    {
        "original_sentence": "Rose and Georg (2021) studied informal cooperation in academic  research",
        "citations": [
            {
                "citation_content": "2021"
            }
        ]
    },
    {
        "original_sentence": "Mejia and Kajikawa (2018) argued that the classification of funders  could be useful in developing funding strategies for policymakers and funders",
        "citations": [
            {
                "citation_content": "2018"
            }
        ]
    },
    {
        "original_sentence": "Doehne and Herfeld (2023) manually investigated acknowledgement sections of papers,  which were published or preprinted in association with the Cowles Foundation between  early 1940 and 1970 to trace the influence of the informal social structure and academic  leaders on the early acceptance of scientific innovations",
        "citations": [
            {
                "citation_content": "2023"
            }
        ]
    },
    {
        "original_sentence": "Recent advances in NER Named Entity Recognition (NER) is a form of NLP that aims to extract named entities  from unstructured text and classify them into predefined categories",
        "citations": [
            {
                "citation_content": "NER"
            }
        ]
    },
    {
        "original_sentence": "The  annotation process is crucial as insufficient or redundant metadata can slow down and bias  a learning process (Pustejovsky & Stubbs, 2012, Chapter 1)",
        "citations": [
            {
                "citation_content": "Pustejovsky & Stubbs, 2012, Chapter 1"
            }
        ]
    },
    {
        "original_sentence": "Scientometrics  1 3 pre-trained transformer architectures (Iovine et  al., 2022)",
        "citations": [
            {
                "citation_content": "Iovine et  al., 2022"
            }
        ]
    },
    {
        "original_sentence": "(2018)  proposed a new character-based contextual string embeddings method",
        "citations": [
            {
                "citation_content": "2018"
            }
        ]
    },
    {
        "original_sentence": "The  training was carried out using a character-based neural language model together with a  Bidirectional LSTM (BiLSTM) sequence-labelling model",
        "citations": [
            {
                "citation_content": "BiLSTM"
            }
        ]
    },
    {
        "original_sentence": "(2018) presented BERT (Bidirectional  Encoder Representations Transformers), a transformer-based language representa- tion model that models the representation of contextualized word embeddings",
        "citations": [
            {
                "citation_content": "2018"
            },
            {
                "citation_content": "Bidirectional  Encoder Representations Transformers"
            }
        ]
    },
    {
        "original_sentence": "(2019) performed an optimization of the BERT model and introduced  RoBERTa (Robustly Optimized BERT Pretraining Approach)",
        "citations": [
            {
                "citation_content": "2019"
            },
            {
                "citation_content": "Robustly Optimized BERT Pretraining Approach"
            }
        ]
    },
    {
        "original_sentence": " (2019) released SciBERT a BERT-based language model pre-trained on a large number  of unlabeled scientific articles from the computer science and biomedical domains",
        "citations": [
            {
                "citation_content": "2019"
            }
        ]
    },
    {
        "original_sentence": "(2022) introduced the SsciBERT, a language model based on BERT  and pre-trained on abstracts published in the Social Science Citation Index (SSCI) journals",
        "citations": [
            {
                "citation_content": "2022"
            },
            {
                "citation_content": "SSCI"
            }
        ]
    },
    {
        "original_sentence": "(2005) uses lists of patterns and domain-specific rules to extract named entities",
        "citations": [
            {
                "citation_content": "2005"
            }
        ]
    },
    {
        "original_sentence": "(2017) developed a rule-based NER model to extract dietary information from  scientific publications",
        "citations": [
            {
                "citation_content": "2017"
            }
        ]
    },
    {
        "original_sentence": "(2022) proposed a cycle-consist- ency approach for NER (CycleNER)",
        "citations": [
            {
                "citation_content": "2022"
            },
            {
                "citation_content": "CycleNER"
            }
        ]
    },
    {
        "original_sentence": "Thus, Kenekayoro (2018) devel- oped a supervised method for the automatic extraction of named entities from academic  bibliographies",
        "citations": [
            {
                "citation_content": "2018"
            }
        ]
    },
    {
        "original_sentence": "The Support Vector Machine classification algorithm (SVM) showed the best  performance",
        "citations": [
            {
                "citation_content": "SVM"
            }
        ]
    },
    {
        "original_sentence": "(2022) proposed a strategy for the identification of software in scientific bio- informatics publications using the combination of SVM and CRF (Conditional Random  Field)",
        "citations": [
            {
                "citation_content": "2022"
            },
            {
                "citation_content": "Conditional Random  Field"
            }
        ]
    },
    {
        "original_sentence": "Kusumegi and Sano (2022) analysed scholarly relationships by analysing acknowl- edged individuals from the acknowledgments statements from eight open-access journals",
        "citations": [
            {
                "citation_content": "2022"
            }
        ]
    },
    {
        "original_sentence": "In the next steps,  scholars were identified among the extracted individuals by mapping them to the Microsoft  Academic Graph (MAG)",
        "citations": [
            {
                "citation_content": "MAG"
            }
        ]
    },
    {
        "original_sentence": "Giles and Councill (2004) developed an automated method for the extraction and  analysis of acknowledgment texts using regular expressions and SVM",
        "citations": [
            {
                "citation_content": "2004"
            }
        ]
    },
    {
        "original_sentence": "Thomer and Weber (2014) used the 4-class Stanford Entity Recognizer (Finkel et al.,  2005) to extract persons, locations, organizations, and miscellaneous entities from the col- lection of bioinformatics texts from PubMed Central’s Open Access corpus",
        "citations": [
            {
                "citation_content": "2014"
            },
            {
                "citation_content": "Finkel et al.,  2005"
            }
        ]
    },
    {
        "original_sentence": "classification without  sacrificing accuracy, nor reliability\" (Thomer & Weber, 2014, p. 1134)",
        "citations": [
            {
                "citation_content": "Thomer & Weber, 2014, p. 1134"
            }
        ]
    },
    {
        "original_sentence": "(2017) introduced a method for extraction of funding organizations and  grants from acknowledgment texts using a combination of sequential learning models: con- ditional random fields (CRF), hidden markov models (HMM), and maximum entropy mod- els (MaxEnt)",
        "citations": [
            {
                "citation_content": "2017"
            },
            {
                "citation_content": "CRF"
            },
            {
                "citation_content": "HMM"
            },
            {
                "citation_content": "MaxEnt"
            }
        ]
    },
    {
        "original_sentence": "Alexandera and Vries (2021) proposed AckNER, a tool for extracting financial informa- tion from the funding or acknowledgment section of a research article",
        "citations": [
            {
                "citation_content": "2021"
            }
        ]
    },
    {
        "original_sentence": "(2022) applied a question-answering (QA) based approach to  identify funding information in acknowledgments texts",
        "citations": [
            {
                "citation_content": "2022"
            },
            {
                "citation_content": "QA"
            }
        ]
    },
    {
        "original_sentence": "(2023)  provided a recent overview of current works in the extraction of knowledge entities",
        "citations": [
            {
                "citation_content": "2023"
            }
        ]
    },
    {
        "original_sentence": "To the best of our knowledge the work of Giles and Councill (2004) is the only  attempt to extract and categorise multiple acknowledged entities",
        "citations": [
            {
                "citation_content": "2004"
            }
        ]
    },
    {
        "original_sentence": "7 AckNER showed better performance as Flair, but is specifically designed to recognize two types of  acknowledged entities (Alexandera & Vries, 2021), which was insufficient for the present project.",
        "citations": [
            {
                "citation_content": "Alexandera & Vries, 2021"
            }
        ]
    },
    {
        "original_sentence": "Scientometrics  1 3 Table 1  Overview of works on NER in scientometrics Paper Area of application and aim of  the studyCorpus Entities Methods and tools Giles and Councill (2004) Extraction of acknowledged enti- ties form acknowledgementsCiteSeer Funding agencies, Companies,  Educational Institutions,  IndividualsSVM for extracting entities and  their manual classification Thomer and Weber (2014) Using NER to improve classifica- tion of acknowledgementsPubMed Central’s Open Access Persons, locations, organizations,  and miscellaneous4-class Stanford Entity Recognizer Kayal et al",
        "citations": [
            {
                "citation_content": "2004"
            },
            {
                "citation_content": "2014"
            }
        ]
    },
    {
        "original_sentence": "(2017) Extraction of funding information  from acknowledgementsPubMed Central’s Open Access Funding bodies, grants CRF, HMM, MaxEnt Kenekayoro (2018) Extraction of biography informa- tion from academic biographiesORCID Award, Location, Organization,  Person, Position, Specializa- tion, OthersSVM Alexandera and Vries (2021) Extraction of funding information  from acknowledgementsTU Delft’s institutional repository Funding bodies, grants SpaCy dependency parser + regu- lar expressions Jiang et al",
        "citations": [
            {
                "citation_content": "2017"
            },
            {
                "citation_content": "2018"
            },
            {
                "citation_content": "2021"
            }
        ]
    },
    {
        "original_sentence": "(2022) Extraction of scientific software  from scientific articles (full  texts) in bioinformaticsbioinformatics journals EnsembleSVMs-CRF Borst et al",
        "citations": [
            {
                "citation_content": "2022"
            },
            {
                "citation_content": "full  texts"
            }
        ]
    },
    {
        "original_sentence": "(2022) Extraction of funding information  from acknowledgementsEconStor Funding bodies, grants Haystack Kusumegi and Sano (2022) Extraction and linking of  acknowledged individuals from  acknowledgementsPLOS Individuals Stanford CoreNLP NER tagger +  MAG",
        "citations": [
            {
                "citation_content": "2022"
            },
            {
                "citation_content": "2022"
            }
        ]
    },
    {
        "original_sentence": "The choice of classification  was inspired by Giles and Councill’s (2004) classification: funding agencies (FUND), cor - porations (COR), universities (UNI), and individuals (IND)",
        "citations": [
            {
                "citation_content": "2004"
            },
            {
                "citation_content": "FUND"
            },
            {
                "citation_content": "COR"
            },
            {
                "citation_content": "UNI"
            },
            {
                "citation_content": "IND"
            }
        ]
    },
    {
        "original_sentence": "For our project, this classifica- tion was enhanced with the miscellaneous (MISC) and grant numbers (GRNB) categories",
        "citations": [
            {
                "citation_content": "MISC"
            },
            {
                "citation_content": "GRNB"
            }
        ]
    },
    {
        "original_sentence": "The Flair NLP framework Flair is an open-sourced NLP framework built on PyTorch (Paszke et  al., 2019), which  is an open-source machine learning library",
        "citations": [
            {
                "citation_content": "Paszke et  al., 2019"
            }
        ]
    },
    {
        "original_sentence": "“The core idea of the framework is to pre- sent a simple, unified interface for conceptually very different types of word and document  embeddings” (Akbik et  al., 2019, p.  54)",
        "citations": [
            {
                "citation_content": "Akbik et  al., 2019, p.  54"
            }
        ]
    },
    {
        "original_sentence": "Flair has three default training algorithms for  NER which were used for the first experiment in the present research: a) NER Model with  Flair Embeddings (later on Flair Embeddings) (Akbik et al., 2018), b) NER Model with  Transformers (later on Transformers) (Schweter & Akbik, 2020), and c) Zero-shot NER  with TARS (later on TARS) (Halder et al., 2020) 8",
        "citations": [
            {
                "citation_content": "later on Flair Embeddings"
            },
            {
                "citation_content": "Akbik et al., 2018"
            },
            {
                "citation_content": "later on Transformers"
            },
            {
                "citation_content": "Schweter & Akbik, 2020"
            },
            {
                "citation_content": "later on TARS"
            },
            {
                "citation_content": "Halder et al., 2020"
            }
        ]
    },
    {
        "original_sentence": "The Flair Embeddings model uses stacked embeddings, i.e., a combination of contex- tual string embeddings (Akbik et al., 2018) with a static embeddings model",
        "citations": [
            {
                "citation_content": "Akbik et al., 2018"
            }
        ]
    },
    {
        "original_sentence": "Stacked  embedding is an important Flair feature, as a combination of different embeddings might  bring better results than their separate uses (Akbik et al., 2019)",
        "citations": [
            {
                "citation_content": "Akbik et al., 2019"
            }
        ]
    },
    {
        "original_sentence": "The Transformers model or FLERT-extension (document-level features for NER) is a  set of settings to perform a NER on the document level using fine-tuning and feature-based  Fig",
        "citations": [
            {
                "citation_content": "document-level features for NER"
            }
        ]
    },
    {
        "original_sentence": "Scientometrics  1 3 LSTM-CRF with the multilingual XML-RoBERTa transformer model (Schweter & Akbik,  2020)",
        "citations": [
            {
                "citation_content": "Schweter & Akbik,  2020"
            }
        ]
    },
    {
        "original_sentence": "The TARS (task-aware representation of sentences) is a transformer-based model,  which allows performing training without any training data (zero-shot learning) or with a  small dataset (few-short learning) (Halder et al., 2020)",
        "citations": [
            {
                "citation_content": "task-aware representation of sentences"
            },
            {
                "citation_content": "zero-shot learning"
            },
            {
                "citation_content": "few-short learning"
            },
            {
                "citation_content": "Halder et al., 2020"
            }
        ]
    },
    {
        "original_sentence": "Training data The Web of Science (WoS) database was used to harvest the training data (funding  acknowledgments).9 From 2008 on, WoS started indexing information about funders and  grants",
        "citations": [
            {
                "citation_content": "WoS"
            }
        ]
    },
    {
        "original_sentence": "As WoS contains millions of metadata records (Singh et al.,  2021), the data chosen for the present study was restricted by year and scientific domain  (for the corpora Nos",
        "citations": [
            {
                "citation_content": "Singh et al.,  2021"
            }
        ]
    },
    {
        "original_sentence": "1, 2, and 3) or additionally by the affiliation country (for corpus No.4)",
        "citations": [
            {
                "citation_content": "for corpus No.4"
            }
        ]
    },
    {
        "original_sentence": "1-3 records from four different scientific domains published  from 2014 to 2019 were considered: two domains from the social sciences (sociology and  economics) and oceanography and computer science",
        "citations": [
            {
                "citation_content": "sociology and  economics"
            }
        ]
    },
    {
        "original_sentence": "Training set (train) Test set (test) Validation set (dev) Total 1 29/27 10/10 10/10 49/47 2 339/282 165/150 150/136 654/441 3 784/657 165/150 150/136 1099/816 4 1148/885 165/150 150/136 1463/1044 Table 3  Number of sentences/texts from each scientific domain in the training corpora Corpus No",
        "citations": [
            {
                "citation_content": "train"
            },
            {
                "citation_content": "test"
            },
            {
                "citation_content": "dev"
            }
        ]
    },
    {
        "original_sentence": "At the same time,  information on technical and instrumental support is more common for the natural and  life sciences domains (Diaz-Faes & Bordons, 2017)",
        "citations": [
            {
                "citation_content": "Diaz-Faes & Bordons, 2017"
            }
        ]
    },
    {
        "original_sentence": "Consequently, there are different amounts  of entities of different types in the training corpora (as Fig.  2 demonstrates), which might  have influenced the training results",
        "citations": [
            {
                "citation_content": "as Fig.  2 demonstrates"
            }
        ]
    },
    {
        "original_sentence": "2, 3, and 4 was evalu- ated on the same training and validation datasets to ensure plausible accuracy (Fig.  3-B)",
        "citations": [
            {
                "citation_content": "Fig.  3-B"
            }
        ]
    },
    {
        "original_sentence": "Scientometrics 1 3 However, training with corpus No.1 was evaluated with the smaller test and validation sets,  as corpus No.1 contains a smaller number of sentences (Fig. 3-A)",
        "citations": [
            {
                "citation_content": "Fig. 3-A"
            }
        ]
    },
    {
        "original_sentence": "As WoS already contains  some indexed funding information, it was decided to develop a semi-automated approach  for data annotation (as Fig.  4 demonstrates) and use indexed information provided by WoS,  therefore, grant numbers were adopted from the WoS indexing unaltered",
        "citations": [
            {
                "citation_content": "as Fig.  4 demonstrates"
            }
        ]
    },
    {
        "original_sentence": "Flair has a pre-trained 4-class NER Flair model (CoNLL-03).13 The model can pre- dict four tags: PER (person name), LOC (location), ORG (organization name), and MISC  (other names)",
        "citations": [
            {
                "citation_content": "CoNLL-03).13 The model can pre- dict four tags: PER (person name"
            },
            {
                "citation_content": "person name"
            },
            {
                "citation_content": "location"
            },
            {
                "citation_content": "organization name"
            },
            {
                "citation_content": "other names"
            }
        ]
    },
    {
        "original_sentence": "Therefore, WoS funding organization  indexing and entities from the ORG and MISC categories were adopted and distinguished  between three categories (FUND, COR, and UNI) using regular expressions",
        "citations": [
            {
                "citation_content": "FUND, COR, and UNI"
            }
        ]
    },
    {
        "original_sentence": "1), as well as the performance of two default FLAIR models (Flair Embeddings  and Transformers) with corpus No.2",
        "citations": [
            {
                "citation_content": "Flair Embeddings  and Transformers"
            }
        ]
    },
    {
        "original_sentence": "For the few-shot TARS,  the training was conducted with the small dataset (corpus No.1), and for Transformers and  Flair Embeddings with a larger dataset (corpus No.2)",
        "citations": [
            {
                "citation_content": "corpus No.1"
            },
            {
                "citation_content": "corpus No.2"
            }
        ]
    },
    {
        "original_sentence": "We applied GloVe (Pennington et  al., 2014) as a static word-level  embedding model",
        "citations": [
            {
                "citation_content": "Pennington et  al., 2014"
            }
        ]
    },
    {
        "original_sentence": "For Transformers, training was initiated with the RoBERTa model (Liu et al., 2019)",
        "citations": [
            {
                "citation_content": "Liu et al., 2019"
            }
        ]
    },
    {
        "original_sentence": "We used a standard approach, where only a linear classifier layer was added on the  top of the transformer, as adding the additional CRF decoder between the transformer and  linear classifier did not increase accuracy compared with this standard approach (Schweter  & Akbik, 2020)",
        "citations": [
            {
                "citation_content": "Schweter  & Akbik, 2020"
            }
        ]
    },
    {
        "original_sentence": "The training was initi- ated with a small learning rate using the Adam Optimisation Algorithm (Kingma & Ba,  2014)",
        "citations": [
            {
                "citation_content": "Kingma & Ba,  2014"
            }
        ]
    },
    {
        "original_sentence": "The training for the few-shot approach was initiated  with the TARS NER model (Halder et al., 2020)",
        "citations": [
            {
                "citation_content": "Halder et al., 2020"
            }
        ]
    },
    {
        "original_sentence": "IND was the best-recognized entity by  training with Flair Embeddings and TARS (both zero- and few-shot) with an F1-score of  0.8 (Flair Embeddings) and 0.86 (TARS) respectively",
        "citations": [
            {
                "citation_content": "both zero- and few-shot"
            },
            {
                "citation_content": "Flair Embeddings"
            },
            {
                "citation_content": "TARS"
            }
        ]
    },
    {
        "original_sentence": "The best results for IND and  GRNB demonstrated Flair embeddings with an F1-score of 0.98 (IND) and 0.96 (GRNB)",
        "citations": [
            {
                "citation_content": "IND"
            },
            {
                "citation_content": "GRNB"
            }
        ]
    },
    {
        "original_sentence": "Miscellaneous demonstrated the worst accuracy  for Flair Embeddings (0.64) and Transformers (0.49), while for TARS the worst accuracy  lies in the COR category with an F1-score of 0.54",
        "citations": [
            {
                "citation_content": "0.64"
            },
            {
                "citation_content": "0.49"
            }
        ]
    },
    {
        "original_sentence": "Training with corpus No.2 showed a significant improvement in training accuracy  (Fig.  5B)",
        "citations": [
            {
                "citation_content": "Fig.  5B"
            }
        ]
    },
    {
        "original_sentence": "1 Algorithm FUND GRNB IND UNI COR MISC accuracy TARS (zero-shot) 0.23 0.33 0.86 0 0 0 0.23 TARS (few-shot) 0.32 0.76 0.86 0 0 0 0.35 Flair embeddings 0.42 0.61 0.80 0 0 0 0.35 Transformers 0.30 0.40 0 0 0 0 0.15 14 Accuracy metrics by type of entity and total accuracy for all experiments can be found in Appendixes   A  and B",
        "citations": [
            {
                "citation_content": "zero-shot"
            },
            {
                "citation_content": "few-shot"
            }
        ]
    },
    {
        "original_sentence": "In this case, the low  performance of the models for the COR and UNI categories could be explained by the  small size of the training sample that contains these categories (see Fig.  2)",
        "citations": [
            {
                "citation_content": "see Fig.  2"
            }
        ]
    },
    {
        "original_sentence": "On the one hand, Flair developers claimed Transformers to be the most effi- cient algorithm (Schweter & Akbik, 2020)",
        "citations": [
            {
                "citation_content": "Schweter & Akbik, 2020"
            }
        ]
    },
    {
        "original_sentence": "On the other, the stacked embeddings are  an important feature of the Flair tool, as a combination of different embeddings might  bring better results than their separate uses (Akbik et  al., 2019)",
        "citations": [
            {
                "citation_content": "Akbik et  al., 2019"
            }
        ]
    },
    {
        "original_sentence": "During the training with three types of  entities (Fig.  6B) IND and GRNB still achieved high F1-scores of 0.96 (IND) and 0.95  (GRNB)",
        "citations": [
            {
                "citation_content": "Fig.  6B"
            },
            {
                "citation_content": "IND"
            },
            {
                "citation_content": "GRNB"
            }
        ]
    },
    {
        "original_sentence": "The  improvement in overall accuracy (Fig.  6D) (0.80 vs",
        "citations": [
            {
                "citation_content": "Fig.  6D"
            }
        ]
    },
    {
        "original_sentence": "As in Experiment 1, the COR category  achieved high precision but low recall, resulting in a low F1-score (0.67)",
        "citations": [
            {
                "citation_content": "0.67"
            }
        ]
    },
    {
        "original_sentence": "For some catego- ries (COR and GRNB) Flair Embeddings combined with RoBERTa performed better than  Transformers but still worse than Flair Embeddings",
        "citations": [
            {
                "citation_content": "COR and GRNB"
            }
        ]
    },
    {
        "original_sentence": "Scientometrics  1 3 model in Experiment 1 (Sect. 3.1)",
        "citations": [
            {
                "citation_content": "Sect. 3.1"
            }
        ]
    },
    {
        "original_sentence": "To achieve comparable results we also retrained, for  now, the best model (Flair Embeddings with Corpus No.2) with the Flair 0.11",
        "citations": [
            {
                "citation_content": "Flair Embeddings with Corpus No.2"
            }
        ]
    },
    {
        "original_sentence": "Overall, the best F1-Score for the FUND category (0.77) was reached with the TARS  algorithm and corpus No.2",
        "citations": [
            {
                "citation_content": "0.77"
            }
        ]
    },
    {
        "original_sentence": "COR gained the best accuracy (0.7) with Flair Embeddings  and corpus No.2 using Flair version 0.9",
        "citations": [
            {
                "citation_content": "0.7"
            }
        ]
    },
    {
        "original_sentence": "The GRNB category showed the best perfor - mance (0.96) with Flair Embeddings trained on the corpus with five types of entities  (Flair Embeddings 5 Ent)",
        "citations": [
            {
                "citation_content": "0.96"
            },
            {
                "citation_content": "Flair Embeddings 5 Ent"
            }
        ]
    },
    {
        "original_sentence": "MISC performed the  best (0.66) with Flair Embeddings trained on Corpus No.4 with Flair version 0.11",
        "citations": [
            {
                "citation_content": "0.66"
            }
        ]
    },
    {
        "original_sentence": "In general, the best overall accuracy of 0.79 (for six entity  types) had the Flair Embeddings model trained on corpus No.2 with Flair version 0.11",
        "citations": [
            {
                "citation_content": "for six entity  types"
            }
        ]
    },
    {
        "original_sentence": "However, fur - ther enlargement of the corpus (in Experiment 3) did not make any progress",
        "citations": [
            {
                "citation_content": "in Experiment 3"
            }
        ]
    },
    {
        "original_sentence": "Some types  of entity, such as IND and GRNB, showed great performance (GRNB with an F1-Score of  0.96 or IND with 0.98) with the small training samples, i.e., 354 entities from the GRNB  category or 439 entities from the IND category",
        "citations": [
            {
                "citation_content": "GRNB with an F1-Score of  0.96 or IND with 0.98"
            }
        ]
    },
    {
        "original_sentence": "In  experiment 1, TARS without training data was able to extract individuals with quite high  accuracy (F-1 score of 0.86)",
        "citations": [
            {
                "citation_content": "F-1 score of 0.86"
            }
        ]
    },
    {
        "original_sentence": "Thus, Flair Embeddings were  trained on the 1-billion words English corpus (Chelba et al., 2013)",
        "citations": [
            {
                "citation_content": "Chelba et al., 2013"
            }
        ]
    },
    {
        "original_sentence": "Previous works showed improvements in downstream tasks using embedding models  fine-tuned for the domain used (Shen et al., 2022; Beltagy et al.., 2019)",
        "citations": [
            {
                "citation_content": "Shen et al., 2022; Beltagy et al.., 2019"
            }
        ]
    },
    {
        "original_sentence": "We are planning to fine-tune  BERT and Flair Embeddings (contextual string embeddings) on a sample of approx",
        "citations": [
            {
                "citation_content": "contextual string embeddings"
            }
        ]
    },
    {
        "original_sentence": " Moreover, further analysis of acknowledged entities showed that the miscellaneous cate- gory contained very inhomogeneous and partly irrelevant data, making the analysis more  complicated (Smirnova & Mayr, 2023)",
        "citations": [
            {
                "citation_content": "Smirnova & Mayr, 2023"
            }
        ]
    },
    {
        "original_sentence": "Analysis of the extracted entities showed that many  entities were extracted correctly, but were assigned to the wrong category (Smirnova &  Mayr, 2023)",
        "citations": [
            {
                "citation_content": "Smirnova &  Mayr, 2023"
            }
        ]
    },
    {
        "original_sentence": "With respect to research question 2, Flair Embeddings showed the best accuracy in  training with corpus No.2 (and version 0.11) and the fastest training time compared to the  other models; thus, it is recommended to further use the Flair Embeddings model for the  recognition of acknowledged entities",
        "citations": [
            {
                "citation_content": "and version 0.11"
            }
        ]
    },
    {
        "original_sentence": "Exploring research question 3 we observed, that the expansion of the size of a training  corpus from very small (corpus No.1) to medium size (corpus No.2) massively increased the  accuracy of all training algorithms",
        "citations": [
            {
                "citation_content": "corpus No.1"
            },
            {
                "citation_content": "corpus No.2"
            }
        ]
    },
    {
        "original_sentence": "The best-performing model (Flair Embedding) was further  retrained with the two bigger corpora, but the following expansion of the training corpus did  not bring further improvement",
        "citations": [
            {
                "citation_content": "Flair Embedding"
            }
        ]
    },
    {
        "original_sentence": "Acknowledgements The original work was funded by the German Center for Higher Education Research  and Science Studies (DZHW) via the project “Mining Acknowledgement Texts in Web of Science  (MinAck)”17",
        "citations": [
            {
                "citation_content": "DZHW"
            }
        ]
    },
    {
        "original_sentence": "Data  access was funded by BMBF (Federal Ministry of Education and Research, Germany) under grant number  01PQ17001",
        "citations": [
            {
                "citation_content": "Federal Ministry of Education and Research, Germany"
            }
        ]
    },
    {
        "original_sentence": "Nina Smirnova received funding from the German Research Foundation (DFG) via the project  “POLLUX”19",
        "citations": [
            {
                "citation_content": "DFG"
            }
        ]
    },
    {
        "original_sentence": "The present paper is an extended version of the paper “Evaluation of Embedding Models for  Automatic Extraction and Classification of Acknowledged Entities in Scientific Documents” (Smirnova &  Mayr, 2022) presented at the 3rd Workshop on Extraction and Evaluation of Knowledge Entities from Sci- entific Documents (EEKE2022)",
        "citations": [
            {
                "citation_content": "Smirnova &  Mayr, 2022"
            },
            {
                "citation_content": "EEKE2022"
            }
        ]
    },
    {
        "original_sentence": "Appendix A: Accuracy metrics by type of entity (label) for all  experiments See Table 5",
        "citations": [
            {
                "citation_content": "label"
            }
        ]
    },
    {
        "original_sentence": "Scientometrics 1 3 Table 5  Accuracy metrics by type of entity (label) for all experiments Algorithm Corpus Version Label Precision Recall F1-score Support Experiment Flair embeddings No.1 9 IND 0.7692 0.8333 0.8000 12 1 Flair embeddings No.1 9 GRNB 0.5385 0.7000 0.6087 10 1 Flair embeddings No.1 9 MISC 0.0000 0.0000 0.0000 6 1 Flair embeddings No.1 9 UNI 0.0000 0.0000 0.0000 3 1 Flair embeddings No.1 9 COR 0.0000 0.0000 0.0000 1 1 Flair embeddings No.1 9 FUND 0.4000 0.4444 0.4211 18 1 Flair embeddings No.2 9 FUND 0.6524 0.7771 0.7093 157 1 Flair embeddings No.2 9 IND 0.9764 0.9831 0.9797 295 1 Flair embeddings No.2 9 GRNB 0.9398 0.9750 0.9571 160 1 Flair embeddings No.2 9 UNI 0.7527 0.7071 0.7292 99 1 Flair embeddings No.2 9 MISC 0.6420 0.6341 0.6380 82 1 Flair embeddings No.2 9 COR 0.8750 0.5833 0.7000 12 1 TARS (pretrained) No.1 9 IND 1.0000 0.7500 0.8571 12 1 TARS (pretrained) No.1 9 GRNB 0.7273 0.8000 0.7619 10 1 TARS (pretrained) No.1 9 MISC 0.0000 0.0000 0.0000 6 1 TARS (pretrained) No.1 9 UNI 0.0000 0.0000 0.0000 3 1 TARS (pretrained) No.1 9 COR 0.0000 0.0000 0.0000 1 1 TARS (pretrained) No.1 9 FUND 0.3158 0.3333 0.3243 18 1 TARS (pretrained) No.2 9 FUND 0.7257 0.8089 0.7651 157 1 TARS (pretrained) No.2 9 IND 0.9281 0.8746 0.9005 295 1 TARS (pretrained) No.2 9 GRNB 0.8895 0.9563 0.9217 160 1 TARS (pretrained) No.2 9 UNI 0.7407 0.6061 0.6667 99 1 TARS (pretrained) No.2 9 MISC 0.6719 0.5244 0.5890 82 1 TARS (pretrained) No.2 9 COR 0.5000 0.5833 0.5385 12 1 Transformers No.1 9 GRNB 0.3000 0.6000 0.4000 10 1 Transformers No.1 9 IND 0.0000 0.0000 0.0000 12 1 Transformers No.1 9 MISC 0.0000 0.0000 0.0000 6 1 Transformers No.1 9 UNI 0.0000 0.0000 0.0000 3 1 Transformers No.1 9 COR 0.0000 0.0000 0.0000 1 1 Transformers No.1 9 FUND 0.2414 0.3889 0.2979 18 1 Transformers No.2 9 FUND 0.6211 0.7516 0.6801 157 1 Transformers No.2 9 IND 0.9346 0.9695 0.9517 295 1 Transformers No.2 9 GRNB 0.8704 0.8812 0.8758 160 1 Transformers No.2 9 UNI 0.6476 0.6869 0.6667 99 1 Transformers No.2 9 MISC 0.4767 0.5000 0.4881 82 1 Transformers No.2 9 COR 0.7500 0.5000 0.6000 12 1 Flair embeddings (3 Ent) No.2 9 IND 0.9577 0.9703 0.9639 303 2 Flair embeddings (3 Ent) No.2 9 ORG 0.6400 0.6154 0.6275 208 2 Flair embeddings (3 Ent) No.2 9 GRNB 0.9286 0.9750 0.9512 160 2 Flair embeddings (5 Ent) No.2 9 IND 0.9764 0.9797 0.9780 295 2 Flair embeddings (5 Ent) No.2 9 GRNB 0.9345 0.9812 0.9573 160 2 Flair embeddings (5 Ent) No.2 9 UNI 0.7802 0.7172 0.7474 99 2 Flair embeddings (5 Ent) No.2 9 COR 0.7500 0.5000 0.6000 12 2 Flair embeddings (5 Ent) No.2 9 FUND 0.6722 0.7707 0.7181 157 2",
        "citations": [
            {
                "citation_content": "label"
            },
            {
                "citation_content": "pretrained"
            },
            {
                "citation_content": "pretrained"
            },
            {
                "citation_content": "pretrained"
            },
            {
                "citation_content": "pretrained"
            },
            {
                "citation_content": "pretrained"
            },
            {
                "citation_content": "pretrained"
            },
            {
                "citation_content": "pretrained"
            },
            {
                "citation_content": "pretrained"
            },
            {
                "citation_content": "pretrained"
            },
            {
                "citation_content": "pretrained"
            },
            {
                "citation_content": "pretrained"
            },
            {
                "citation_content": "pretrained"
            },
            {
                "citation_content": "3 Ent"
            },
            {
                "citation_content": "3 Ent"
            },
            {
                "citation_content": "3 Ent"
            },
            {
                "citation_content": "5 Ent"
            },
            {
                "citation_content": "5 Ent"
            },
            {
                "citation_content": "5 Ent"
            },
            {
                "citation_content": "5 Ent"
            },
            {
                "citation_content": "5 Ent"
            }
        ]
    },
    {
        "original_sentence": "Scientometrics  1 3 Appendix B: Overall accuracy for all experiments See Table 6.Rows are sorted by experiment number and algorithmTable 5  (continued) Algorithm Corpus Version Label Precision Recall F1-score Support Experiment Flair embeddings (RoB- ERTa)No.2 9 IND 0.9206 0.9831 0.9508 295 2 Flair embeddings (RoB- ERTa)No.2 9 GRNB 0.8896 0.9062 0.8978 160 2 Flair embeddings (RoB- ERTa)No.2 9 UNI 0.5963 0.6566 0.6250 99 2 Flair embeddings (RoB- ERTa)No.2 9 MISC 0.4135 0.5244 0.4624 82 2 Flair embeddings (RoB- ERTa)No.2 9 COR 1.0000 0.5000 0.6667 12 2 Flair embeddings (RoB- ERTa)No.2 9 FUND 0.6096 0.7261 0.6628 157 2 Flair embeddings No.2 11 GRNB 0.9345 0.9812 0.9573 160 3 Flair embeddings No.2 11 IND 0.9797 0.9831 0.9814 295 3 Flair embeddings No.2 11 FUND 0.7027 0.8280 0.7602 157 3 Flair embeddings No.2 11 UNI 0.7684 0.7374 0.7526 99 3 Flair embeddings No.2 11 MISC 0.6543 0.6463 0.6503 82 3 Flair embeddings No.2 11 COR 0.7500 0.5000 0.6000 12 3 Flair embeddings No.3 11 UNI 0.8000 0.7273 0.7619 99 3 Flair embeddings No.3 11 IND 0.9731 0.9797 0.9764 295 3 Flair embeddings No.3 11 GRNB 0.9281 0.9688 0.9480 160 3 Flair embeddings No.3 11 COR 0.7500 0.5000 0.6000 12 3 Flair embeddings No.3 11 MISC 0.6571 0.5610 0.6053 82 3 Flair embeddings No.3 11 FUND 0.6757 0.7962 0.7310 157 3 Flair embeddings No.4 11 MISC 0.7424 0.5976 0.6622 82 3 Flair embeddings No.4 11 COR 0.8571 0.5000 0.6316 12 3 Flair embeddings No.4 11 UNI 0.7753 0.6970 0.7340 99 3 Flair embeddings No.4 11 IND 0.9698 0.9797 0.9747 295 3 Flair embeddings No.4 11 FUND 0.6823 0.8344 0.7507 157 3 Flair embeddings No.4 11 GRNB 0.9162 0.9563 0.9358 160 3",
        "citations": [
            {
                "citation_content": "continued"
            }
        ]
    },
    {
        "original_sentence": "(2018)",
        "citations": [
            {
                "citation_content": "2018"
            }
        ]
    },
    {
        "original_sentence": "In 2018,  27th International Conference on Computational Linguistics (pp. 1638–1649)",
        "citations": [
            {
                "citation_content": "pp. 1638–1649"
            }
        ]
    },
    {
        "original_sentence": "(2021)",
        "citations": [
            {
                "citation_content": "2021"
            }
        ]
    },
    {
        "original_sentence": "In BIR 2021: 11th International Workshop on Bibliometric-enhanced  Information Retrieval at ECIR (pp. 102–110)",
        "citations": [
            {
                "citation_content": "pp. 102–110"
            }
        ]
    },
    {
        "original_sentence": "(2019)",
        "citations": [
            {
                "citation_content": "2019"
            }
        ]
    },
    {
        "original_sentence": " In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing  and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)   (pp. 3613–3618)",
        "citations": [
            {
                "citation_content": "EMNLP-IJCNLP"
            },
            {
                "citation_content": "pp. 3613–3618"
            }
        ]
    },
    {
        "original_sentence": "Association for Computational Linguistics.Table 6  Overall accuracy for all experiments Rows are sorted by experiment number and algorithmAlgorithm Corpus Version Accuracy Experiment Flair embeddings No.2 9 0.7702 1 Flair embeddings No.1 9 0.3472 1 TARS (pretrained) No.2 9 0.7113 1 TARS (pretrained) No.1 9 0.3485 1 Transformers No.2 9 0.6783 1 Transformers No.1 9 0.1477 1 Flair Embeddings (3 Entity Types) No.2 9 0.7536 2 Flair embeddings (5 Entity Types) No.2 9 0.7990 2 Flair embeddings + RoBERTa No.2 9 0.6697 2 Flair Embeddings No.2 11 0.7869 3 Flair embeddings No.4 11 0.7814 3 Flair embeddings No.3 11 0.7691 3",
        "citations": [
            {
                "citation_content": "pretrained"
            },
            {
                "citation_content": "pretrained"
            },
            {
                "citation_content": "3 Entity Types"
            },
            {
                "citation_content": "5 Entity Types"
            }
        ]
    },
    {
        "original_sentence": "(2022)",
        "citations": [
            {
                "citation_content": "2022"
            }
        ]
    },
    {
        "original_sentence": "(2013)",
        "citations": [
            {
                "citation_content": "2013"
            }
        ]
    },
    {
        "original_sentence": "(2022)",
        "citations": [
            {
                "citation_content": "2022"
            }
        ]
    },
    {
        "original_sentence": "(1995)",
        "citations": [
            {
                "citation_content": "1995"
            }
        ]
    },
    {
        "original_sentence": "(1995)",
        "citations": [
            {
                "citation_content": "1995"
            }
        ]
    },
    {
        "original_sentence": "(2018)",
        "citations": [
            {
                "citation_content": "2018"
            }
        ]
    },
    {
        "original_sentence": "(2017)",
        "citations": [
            {
                "citation_content": "2017"
            }
        ]
    },
    {
        "original_sentence": "(2023)",
        "citations": [
            {
                "citation_content": "2023"
            }
        ]
    },
    {
        "original_sentence": "(2022)",
        "citations": [
            {
                "citation_content": "2022"
            }
        ]
    },
    {
        "original_sentence": "(2017)",
        "citations": [
            {
                "citation_content": "2017"
            }
        ]
    },
    {
        "original_sentence": "(2005)",
        "citations": [
            {
                "citation_content": "2005"
            }
        ]
    },
    {
        "original_sentence": "(2005)",
        "citations": [
            {
                "citation_content": "2005"
            }
        ]
    },
    {
        "original_sentence": "In Proceedings of the 43rd Annual Meeting of the Associa- tion for Computational Linguistics (ACL’05), Ann Arbor, Michigan (pp",
        "citations": [
            {
                "citation_content": "ACL’05"
            }
        ]
    },
    {
        "original_sentence": "(2004)",
        "citations": [
            {
                "citation_content": "2004"
            }
        ]
    },
    {
        "original_sentence": "(2020)",
        "citations": [
            {
                "citation_content": "2020"
            }
        ]
    },
    {
        "original_sentence": "In Proceedings of the 28th International Conference on Computational  Linguistics, Barcelona, Spain (Online) (pp",
        "citations": [
            {
                "citation_content": "Online"
            }
        ]
    },
    {
        "original_sentence": "(2022)",
        "citations": [
            {
                "citation_content": "2022"
            }
        ]
    },
    {
        "original_sentence": "(2022)",
        "citations": [
            {
                "citation_content": "2022"
            }
        ]
    },
    {
        "original_sentence": "In Proceedings of the ACM Web Conference 2022   (pp. 2916–2924)",
        "citations": [
            {
                "citation_content": "pp. 2916–2924"
            }
        ]
    },
    {
        "original_sentence": "(2022)",
        "citations": [
            {
                "citation_content": "2022"
            }
        ]
    },
    {
        "original_sentence": "(1991)",
        "citations": [
            {
                "citation_content": "1991"
            }
        ]
    },
    {
        "original_sentence": "(2017)",
        "citations": [
            {
                "citation_content": "2017"
            }
        ]
    },
    {
        "original_sentence": "(2018)",
        "citations": [
            {
                "citation_content": "2018"
            }
        ]
    },
    {
        "original_sentence": "(2014)",
        "citations": [
            {
                "citation_content": "2014"
            }
        ]
    },
    {
        "original_sentence": "(2022)",
        "citations": [
            {
                "citation_content": "2022"
            }
        ]
    },
    {
        "original_sentence": "(2019)",
        "citations": [
            {
                "citation_content": "2019"
            }
        ]
    },
    {
        "original_sentence": "(1972)",
        "citations": [
            {
                "citation_content": "1972"
            }
        ]
    },
    {
        "original_sentence": "(2017)",
        "citations": [
            {
                "citation_content": "2017"
            }
        ]
    },
    {
        "original_sentence": "(1991)",
        "citations": [
            {
                "citation_content": "1991"
            }
        ]
    },
    {
        "original_sentence": "(2018)",
        "citations": [
            {
                "citation_content": "2018"
            }
        ]
    },
    {
        "original_sentence": "(2019)",
        "citations": [
            {
                "citation_content": "2019"
            }
        ]
    },
    {
        "original_sentence": "(2019)",
        "citations": [
            {
                "citation_content": "2019"
            }
        ]
    },
    {
        "original_sentence": "(2017)",
        "citations": [
            {
                "citation_content": "2017"
            }
        ]
    },
    {
        "original_sentence": "(2014)",
        "citations": [
            {
                "citation_content": "2014"
            }
        ]
    },
    {
        "original_sentence": " In Empirical Methods in Natural Language Processing (EMNLP) (pp",
        "citations": [
            {
                "citation_content": "EMNLP"
            }
        ]
    },
    {
        "original_sentence": "(2012)",
        "citations": [
            {
                "citation_content": "2012"
            }
        ]
    },
    {
        "original_sentence": "(2021)",
        "citations": [
            {
                "citation_content": "2021"
            }
        ]
    },
    {
        "original_sentence": "(2003)",
        "citations": [
            {
                "citation_content": "2003"
            }
        ]
    },
    {
        "original_sentence": "In Proceedings of the Seventh Conference on Natural Lan- guage Learning at HLT-NAACL (pp. 142–147)",
        "citations": [
            {
                "citation_content": "pp. 142–147"
            }
        ]
    },
    {
        "original_sentence": "(2020)",
        "citations": [
            {
                "citation_content": "2020"
            }
        ]
    },
    {
        "original_sentence": "(2022)",
        "citations": [
            {
                "citation_content": "2022"
            }
        ]
    },
    {
        "original_sentence": "(2021)",
        "citations": [
            {
                "citation_content": "2021"
            }
        ]
    },
    {
        "original_sentence": "(2022)",
        "citations": [
            {
                "citation_content": "2022"
            }
        ]
    },
    {
        "original_sentence": "In 3rd Workshop on Extraction and Evalu- ation of Knowledge Entities from Scientific Documents 2022 (EEKE 2022) (pp. 48–55)",
        "citations": [
            {
                "citation_content": "EEKE 2022"
            },
            {
                "citation_content": "pp. 48–55"
            }
        ]
    },
    {
        "original_sentence": "(2023)",
        "citations": [
            {
                "citation_content": "2023"
            }
        ]
    },
    {
        "original_sentence": "(2020)",
        "citations": [
            {
                "citation_content": "2020"
            }
        ]
    },
    {
        "original_sentence": "(2014)",
        "citations": [
            {
                "citation_content": "2014"
            }
        ]
    },
    {
        "original_sentence": "In  iConference 2014 Proceedings (pp. 1133 – 1138)",
        "citations": [
            {
                "citation_content": "pp. 1133 – 1138"
            }
        ]
    },
    {
        "original_sentence": "(2011)",
        "citations": [
            {
                "citation_content": "2011"
            }
        ]
    },
    {
        "original_sentence": "(2020)",
        "citations": [
            {
                "citation_content": "2020"
            }
        ]
    },
    {
        "original_sentence": "In Proceedings of the 2020 Conference on  Empirical Methods in Natural Language Processing (EMNLP) (pp. 6442–6454)",
        "citations": [
            {
                "citation_content": "EMNLP"
            },
            {
                "citation_content": "pp. 6442–6454"
            }
        ]
    },
    {
        "original_sentence": "(2020)",
        "citations": [
            {
                "citation_content": "2020"
            }
        ]
    },
    {
        "original_sentence": "(2023)",
        "citations": [
            {
                "citation_content": "2023"
            }
        ]
    }
]