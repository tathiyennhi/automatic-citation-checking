ID,Citation,Child Citation,Context,Full Reference,Paper Title,Authors,Year,Matched
1.1,"Kassirer  &  Angell,  1991,  p.  1511","Kassirer  &  Angell,  1991,  p.  1511","Text mining · Flair NLP-framework

 *  Nina Smirnova 

nina.smirnova@gesis.org

Philipp Mayr 
philipp.mayr@gesis.org

1  GESIS – Leibniz Institute for the Social Sciences, Unter Sachsenhausen 6-8, 50667 Cologne, 

Germany

Vol.:(0123456789)1 3 
 
 
Scientometrics

Introduction

Acknowledgments  in  scientific  papers  are  short  texts  where  the  author(s)  “identify  those 
who  made  special  intellectual  or  technical  contribution  to  a  study  that  are  not  sufficient 
to  qualify  them  for  authorship”  (Kassirer  &  Angell,  1991,  p.  1511).","Kassirer, J. P., & Angell, M. (1991). On authorship and acknowledgments. The New England Journal of",On authorship and acknowledgments,"Kassirer, J. P., & Angell, M.",1991,Yes
2.1,"Giles & Councill, 2004, p. 17599","Giles & Councill, 2004, p. 17599","Acknowledgments of 
technical and instrumental support may reveal “indirect contributions of research labora-
tories and universities to research activities” (Giles & Councill, 2004, p. 17599).","Giles,  C.  L.,  &  Councill,  I.  G.  (2004).  Who  gets  acknowledged:  Measuring  scientific  contributions  through  automatic  acknowledgment  indexing.  Proceedings  of  the  National  Academy  of  Sciences, 101(51), 17599–17604. https:// doi. org/ 10. 1073/ pnas. 04077 43101",Who  gets  acknowledged:  Measuring  scientific  contributions  through  automatic  acknowledgment  indexing,"Giles,  C.  L.,  &  Councill,  I.  G.",2004,Yes
3.1,"Dzieżyc 
& Kazienko, 2022","Dzieżyc 
& Kazienko, 2022","The  analysis  of  acknowledgments  is  particularly  interesting  as  acknowledgments  may 
give an insight into aspects of the scientific community, such as reward systems (Dzieżyc 
& Kazienko, 2022), collaboration patterns, and hidden research trends (Giles & Councill, 
2004; Diaz-Faes & Bordons, 2017).","Dzieżyc, M., & Kazienko, P. (2022). Effectiveness of research grants funded by European research coun- cil  and  polish  national  science  centre.  Journal  of  Informetrics,  16(1),  101243.  https:// doi. org/ 10. 1016/j. joi. 2021. 101243",Effectiveness of research grants funded by European research coun- cil  and  polish  national  science  centre,"Dzieżyc, M., & Kazienko, P.",2022,Yes
4.1,"Giles & Councill, 
2004; Diaz-Faes & Bordons, 2017","Giles & Councill, 
2004","The  analysis  of  acknowledgments  is  particularly  interesting  as  acknowledgments  may 
give an insight into aspects of the scientific community, such as reward systems (Dzieżyc 
& Kazienko, 2022), collaboration patterns, and hidden research trends (Giles & Councill, 
2004; Diaz-Faes & Bordons, 2017).","Giles,  C.  L.,  &  Councill,  I.  G.  (2004).  Who  gets  acknowledged:  Measuring  scientific  contributions  through  automatic  acknowledgment  indexing.  Proceedings  of  the  National  Academy  of  Sciences, 101(51), 17599–17604. https:// doi. org/ 10. 1073/ pnas. 04077 43101",Who  gets  acknowledged:  Measuring  scientific  contributions  through  automatic  acknowledgment  indexing,"Giles,  C.  L.,  &  Councill,  I.  G.",2004,Yes
4.2,"Giles & Councill, 
2004; Diaz-Faes & Bordons, 2017","Diaz-Faes & Bordons, 2017","The  analysis  of  acknowledgments  is  particularly  interesting  as  acknowledgments  may 
give an insight into aspects of the scientific community, such as reward systems (Dzieżyc 
& Kazienko, 2022), collaboration patterns, and hidden research trends (Giles & Councill, 
2004; Diaz-Faes & Bordons, 2017).","Diaz-Faes, A. A., & Bordons, M. (2017). Making visible the invisible through the analysis of acknowl- edgements  in  the  humanities. Aslib  Journal  of  Information  Management,  69(5),  576–590. https:// doi. org/ 10. 1108/ AJIM- 01- 2017- 0008",Making visible the invisible through the analysis of acknowl- edgements  in  the  humanities,"Diaz-Faes, A. A., & Bordons, M.",2017,Yes
5.1,"Alexandera & 
Vries,  2021;  Kayal  et  al.,  2017;  Borst  et  al.,  2022","Alexandera & 
Vries,  2021","To our knowledge, previous works on automatic acknowledgment analysis were mostly 
concerned with the extraction of funding organizations and grant numbers (Alexandera & 
Vries,  2021;  Kayal  et  al.,  2017;  Borst  et  al.,  2022)  or  classification  of  acknowledgment 
texts (Song et al., 2020; Hubbard et al., 2022).","Alexandera, D. & Vries, A. P. (2021). This research is funded by...”: Named Entity Recognition of financial  information in research papers. In BIR 2021: 11th International Workshop on Bibliometric-enhanced",This research is funded by,"Alexandera, D. & Vries, A. P.",2021,Yes
5.2,"Alexandera & 
Vries,  2021;  Kayal  et  al.,  2017;  Borst  et  al.,  2022","Kayal  et  al.,  2017","To our knowledge, previous works on automatic acknowledgment analysis were mostly 
concerned with the extraction of funding organizations and grant numbers (Alexandera & 
Vries,  2021;  Kayal  et  al.,  2017;  Borst  et  al.,  2022)  or  classification  of  acknowledgment 
texts (Song et al., 2020; Hubbard et al., 2022).","Diaz-Faes, A. A., & Bordons, M. (2017). Making visible the invisible through the analysis of acknowl- edgements  in  the  humanities. Aslib  Journal  of  Information  Management,  69(5),  576–590. https:// doi. org/ 10. 1108/ AJIM- 01- 2017- 0008",Making visible the invisible through the analysis of acknowl- edgements  in  the  humanities,"Diaz-Faes, A. A., & Bordons, M.",2017,Yes
5.3,"Alexandera & 
Vries,  2021;  Kayal  et  al.,  2017;  Borst  et  al.,  2022","Borst  et  al.,  2022","To our knowledge, previous works on automatic acknowledgment analysis were mostly 
concerned with the extraction of funding organizations and grant numbers (Alexandera & 
Vries,  2021;  Kayal  et  al.,  2017;  Borst  et  al.,  2022)  or  classification  of  acknowledgment 
texts (Song et al., 2020; Hubbard et al., 2022).","Borst,  T.,  Mielck,  J.,  Nannt,  M.,  &  Riese,  W.  (2022).  Extracting  funder  information  from  scien- tific  papers—Experiences  with  question  answering.  In  Silvello,  G.,  O.  Corcho,  P.  Manghi,  G.M.",Extracting  funder  information  from  scien- tific  papers—Experiences  with  question  answering,"Borst,  T.,  Mielck,  J.,  Nannt,  M.,  &  Riese,  W.",2022,Yes
6.1,"Song et al., 2020; Hubbard et al., 2022","Song et al., 2020","To our knowledge, previous works on automatic acknowledgment analysis were mostly 
concerned with the extraction of funding organizations and grant numbers (Alexandera & 
Vries,  2021;  Kayal  et  al.,  2017;  Borst  et  al.,  2022)  or  classification  of  acknowledgment 
texts (Song et al., 2020; Hubbard et al., 2022).","Song,  M.,  Kang,  K.  Y.,  Timakum,  T.,  &  Zhang,  X.  (2020).  Examining  influential  factors  for  acknowl- edgements  classification  using  supervised  learning.  PLoS  ONE.  https:// doi. org/ 10. 1371/ journ al. pone. 02289 28",Examining  influential  factors  for  acknowl- edgements  classification  using  supervised  learning,"Song,  M.,  Kang,  K.  Y.,  Timakum,  T.,  &  Zhang,  X.",2020,Yes
6.2,"Song et al., 2020; Hubbard et al., 2022","Hubbard et al., 2022","To our knowledge, previous works on automatic acknowledgment analysis were mostly 
concerned with the extraction of funding organizations and grant numbers (Alexandera & 
Vries,  2021;  Kayal  et  al.,  2017;  Borst  et  al.,  2022)  or  classification  of  acknowledgment 
texts (Song et al., 2020; Hubbard et al., 2022).","Hubbard, D., Laddusaw, S., Tan, Q., & Hu, X. (2022). Analysis of acknowledgments of libraries in the  journal literature using machine learning. Proceedings of the Association for Information Science and Technology, 59(1), 709–711. https:// doi. org/ 10. 1002/ pra2. 698",Analysis of acknowledgments of libraries in the  journal literature using machine learning,"Hubbard, D., Laddusaw, S., Tan, Q., & Hu, X.",2022,Yes
7.1,"Rose & Georg, 2021; Kusumegi & 
Sano,  2022","Rose & Georg, 2021","Analysis of the acknowledged individuals 
provides insight into informal scientific collaboration (Rose & Georg, 2021; Kusumegi & 
Sano,  2022).","Rose,  M.,  &  Georg,  C.  P.  (2021).  What  5,000  acknowledgements  tell  us  about  informal  collaboration  in financial economics. Research Policy, 50, 104236. https:// doi. org/ 10. 1016/j. respol. 2021. 104236","What  5,000  acknowledgements  tell  us  about  informal  collaboration  in financial economics","Rose,  M.,  &  Georg,  C.  P.",2021,Yes
7.2,"Rose & Georg, 2021; Kusumegi & 
Sano,  2022","Kusumegi & 
Sano,  2022","Analysis of the acknowledged individuals 
provides insight into informal scientific collaboration (Rose & Georg, 2021; Kusumegi & 
Sano,  2022).","Kusumegi, K., & Sano, Y. (2022). Dataset of identified scholars mentioned in acknowledgement state-  ments. Scientific Data, 9(1), 461. https:// doi. org/ 10. 1038/ s41597- 022- 01585-y",Dataset of identified scholars mentioned in acknowledgement state-  ments,"Kusumegi, K., & Sano, Y.",2022,Yes
8.1,"Chen  et  al.,  2022","Chen  et  al.,  2022","Acknowledged  universities  and  corporations  reveal  interactions  and  knowl-
edge  exchange  between  industry  and  universities  (Chen  et  al.,  2022).","Shen,  S.,  Liu,  J.,  Lin,  L.,  Huang,  Y.,  Zhang,  L.,  Liu,  C.,  Feng,  Y.,  &  Wang,  D.  (2022).  SsciBERT:  A  pre-trained  language  model  for  social  science  texts.  Scientometrics.  https:// doi. org/ 10. 1007/ s11192- 022- 04602-4",SsciBERT:  A  pre-trained  language  model  for  social  science  texts,"Shen,  S.,  Liu,  J.,  Lin,  L.,  Huang,  Y.,  Zhang,  L.,  Liu,  C.,  Feng,  Y.,  &  Wang,  D.",2022,Yes
9.1,"Sang  et  al.,  2003","Sang  et  al.,  2003","CoNLL-2003  corpus  (Sang  et  al.,  2003)  is  a  benchmark  dataset 
for  language-independent  named  entity  recognition,  i.e.,  designed  to  train  and  evaluate 
NER models.","Sang, T. K., & E. F., & De Meulder, F. (2003). Introduction to the CoNLL-2003 shared task: Language- independent named entity recognition. In Proceedings of the Seventh Conference on Natural Lan- guage Learning at HLT-NAACL (pp. 142–147).",Introduction to the CoNLL-2003 shared task: Language- independent named entity recognition,"Sang, T. K., & E. F., & De Meulder, F.",2003,Yes
10.1,"Smirnova & Mayr, 2022","Smirnova & Mayr, 2022","com/ produ cts_ tools/ multi disci plina ry/ webof scien ce/ fundi ngsea rch/.

1 3 
Scientometrics 

The present paper is an extended version of the article (Smirnova & Mayr, 2022)2 pre-
sented at the 3rd Workshop on Extraction and Evaluation of Knowledge Entities from Sci-
entific Documents (EEKE2022).3 Flair, an open-source natural language processing (NLP) 
framework (Akbik et al., 2019) is used in our study to create a tool for the extraction of 
acknowledged entities because this library is easily customizable.","Smirnova, N., & Mayr, P. (2022). Evaluation of embedding models for automatic extraction and classifi- cation of acknowledged entities in scientific documents. In 3rd Workshop on Extraction and Evalu- ation of Knowledge Entities from Scientific Documents 2022 (EEKE 2022) (pp. 48–55). CEUR-WS. org.",Evaluation of embedding models for automatic extraction and classifi- cation of acknowledged entities in scientific documents,"Smirnova, N., & Mayr, P.",2022,Yes
11.1,"Akbik et al., 2019","Akbik et al., 2019","com/ produ cts_ tools/ multi disci plina ry/ webof scien ce/ fundi ngsea rch/.

1 3 
Scientometrics 

The present paper is an extended version of the article (Smirnova & Mayr, 2022)2 pre-
sented at the 3rd Workshop on Extraction and Evaluation of Knowledge Entities from Sci-
entific Documents (EEKE2022).3 Flair, an open-source natural language processing (NLP) 
framework (Akbik et al., 2019) is used in our study to create a tool for the extraction of 
acknowledged entities because this library is easily customizable.","N., Antiga, L., Desmaison, A., Köpf, A., Yang, E., DeVito, Z., Raison, M., Tejani, A., Chilamkur- thy,  S.,  Steiner,  B.,  Fang,  L.,  Bai,  J.,  &  Chintala,  S.  (2019).  PyTorch:  An  imperative  style,  high- performance deep learning library. arXiv: 1912. 01703 [cs, stat].","PyTorch:  An  imperative  style,  high- performance deep learning library","N., Antiga, L., Desmaison, A., Köpf, A., Yang, E., DeVito, Z., Raison, M., Tejani, A., Chilamkur- thy,  S.,  Steiner,  B.,  Fang,  L.,  Bai,  J.,  &  Chintala,  S.",2019,Yes
12.1,"Giles 
&  Councill,  2004;  Paul-Hus  et  al.,  2017;  Paul-Hus  &  Desrochers,  2019;  Mccain,  2017","Giles 
&  Councill,  2004","Most of the previous works on acknowledgment analysis were limited 
by  the  manual  evaluation  of  data  and  therefore  by  the  amount  of  processed  data  (Giles 
&  Councill,  2004;  Paul-Hus  et  al.,  2017;  Paul-Hus  &  Desrochers,  2019;  Mccain,  2017).","Giles,  C.  L.,  &  Councill,  I.  G.  (2004).  Who  gets  acknowledged:  Measuring  scientific  contributions  through  automatic  acknowledgment  indexing.  Proceedings  of  the  National  Academy  of  Sciences, 101(51), 17599–17604. https:// doi. org/ 10. 1073/ pnas. 04077 43101",Who  gets  acknowledged:  Measuring  scientific  contributions  through  automatic  acknowledgment  indexing,"Giles,  C.  L.,  &  Councill,  I.  G.",2004,Yes
12.2,"Giles 
&  Councill,  2004;  Paul-Hus  et  al.,  2017;  Paul-Hus  &  Desrochers,  2019;  Mccain,  2017","Paul-Hus  et  al.,  2017","Most of the previous works on acknowledgment analysis were limited 
by  the  manual  evaluation  of  data  and  therefore  by  the  amount  of  processed  data  (Giles 
&  Councill,  2004;  Paul-Hus  et  al.,  2017;  Paul-Hus  &  Desrochers,  2019;  Mccain,  2017).","Diaz-Faes, A. A., & Bordons, M. (2017). Making visible the invisible through the analysis of acknowl- edgements  in  the  humanities. Aslib  Journal  of  Information  Management,  69(5),  576–590. https:// doi. org/ 10. 1108/ AJIM- 01- 2017- 0008",Making visible the invisible through the analysis of acknowl- edgements  in  the  humanities,"Diaz-Faes, A. A., & Bordons, M.",2017,Yes
12.3,"Giles 
&  Councill,  2004;  Paul-Hus  et  al.,  2017;  Paul-Hus  &  Desrochers,  2019;  Mccain,  2017","Paul-Hus  &  Desrochers,  2019","Most of the previous works on acknowledgment analysis were limited 
by  the  manual  evaluation  of  data  and  therefore  by  the  amount  of  processed  data  (Giles 
&  Councill,  2004;  Paul-Hus  et  al.,  2017;  Paul-Hus  &  Desrochers,  2019;  Mccain,  2017).","Paul-Hus, A., & Desrochers, N. (2019). Acknowledgements are not just thank you notes: A qualitative  analysis  of  acknowledgements  content  in  scientific  articles  and  reviews  published  in  2015.  PLoS",Acknowledgements are not just thank you notes: A qualitative  analysis  of  acknowledgements  content  in  scientific  articles  and  reviews  published  in  2015,"Paul-Hus, A., & Desrochers, N.",2019,Yes
12.4,"Giles 
&  Councill,  2004;  Paul-Hus  et  al.,  2017;  Paul-Hus  &  Desrochers,  2019;  Mccain,  2017","Mccain,  2017","Most of the previous works on acknowledgment analysis were limited 
by  the  manual  evaluation  of  data  and  therefore  by  the  amount  of  processed  data  (Giles 
&  Councill,  2004;  Paul-Hus  et  al.,  2017;  Paul-Hus  &  Desrochers,  2019;  Mccain,  2017).","Mccain,  K.  (2017).  Beyond  Garfield’s  citation  index:  An  assessment  of  some  issues  in  building  a  per- sonal name acknowledgments index. Scientometrics. https:// doi. org/ 10. 1007/ s11192- 017- 2598-1",Beyond  Garfield’s  citation  index:  An  assessment  of  some  issues  in  building  a  per- sonal name acknowledgments index,"Mccain,  K.",2017,Yes
13.1,"as  cited 
in Cronin, 1995","as  cited 
in Cronin, 1995","(as  cited 
in Cronin, 1995) and comprised three categories: facilities, access to data, and help of indi-
viduals.","Cronin, B. (1995). The Scholar’s courtesy: The role of acknowledgement in the primary communication   process. Taylor Graham.",The Scholar’s courtesy: The role of acknowledgement in the primary communication   process,"Cronin, B.",1995,Yes
14.1,"Pustejovsky & Stubbs, 2012, Chapter 1","Pustejovsky & Stubbs, 2012, Chapter 1","The 
annotation process is crucial as insufficient or redundant metadata can slow down and bias 
a learning process (Pustejovsky & Stubbs, 2012, Chapter 1).","Pustejovsky,  J.,  &  Stubbs,  A.  (2012).  Natural  language  annotation  for  machine  learning.  O’Reilly",Natural  language  annotation  for  machine  learning,"Pustejovsky,  J.,  &  Stubbs,  A.",2012,Yes
15.1,"Iovine  et  al.,  2022","Iovine  et  al.,  2022","The 
state-of-the-art  models  are  based  on  deep  recurrent  models,  convolution-based,  or 

1 3 
Scientometrics 

pre-trained  transformer  architectures  (Iovine  et  al.,  2022).","Iovine,  A.,  Fang,  A.,  Fetahu,  B.,  Rokhlenko,  O.,  &  Malmasi,  S.  (2022).  CycleNER:  An  unsupervised  training approach for named entity recognition. In Proceedings of the ACM Web Conference 2022 (pp. 2916–2924). ACM.",CycleNER:  An  unsupervised  training approach for named entity recognition,"Iovine,  A.,  Fang,  A.,  Fetahu,  B.,  Rokhlenko,  O.,  &  Malmasi,  S.",2022,Yes
16.1,"Finkel  et  al., 
2005","Finkel  et  al., 
2005","Thomer  and  Weber  (2014)  used  the  4-class  Stanford  Entity  Recognizer  (Finkel  et  al., 
2005) to extract persons, locations, organizations, and miscellaneous entities from the col-
lection  of  bioinformatics  texts  from  PubMed  Central’s  Open  Access  corpus.","Finkel, J.R., Grenager, T., & Manning, C. (2005). Incorporating non-local information into information  extraction systems by Gibbs sampling. In Proceedings of the 43rd Annual Meeting of the Associa- tion for Computational Linguistics (ACL’05), Ann Arbor, Michigan (pp. 363–370). Association for",Incorporating non-local information into information  extraction systems by Gibbs sampling,"Finkel, J.R., Grenager, T., & Manning, C.",2005,Yes
17.1,"Thomer & Weber, 2014, p. 1134","Thomer & Weber, 2014, p. 1134","The  aim  of 
the study was to determine an approach to ""increase the speed of ... classification without 
sacrificing accuracy, nor reliability"" (Thomer & Weber, 2014, p. 1134).","Thomer, A. K., & Weber, N. M. (2014). Using named entity recognition as a classification heuristic. In   iConference 2014 Proceedings (pp. 1133 – 1138). iSchools.",Using named entity recognition as a classification heuristic,"Thomer, A. K., & Weber, N. M.",2014,Yes
18.1,"Alexandera & Vries, 2021","Alexandera & Vries, 2021","Furthermore, as far as we know, there was no research done concerning the eval-
uation of embedding models for extraction of information from acknowledgement texts 
and  no  tool  for  automatic  extraction  of  different  kinds  of  acknowledged  entities  was 
developed.

7  AckNER  showed  better  performance  as  Flair,  but  is  specifically  designed  to  recognize  two  types  of 
acknowledged entities (Alexandera & Vries, 2021), which was insufficient for the present project.","Alexandera, D. & Vries, A. P. (2021). This research is funded by...”: Named Entity Recognition of financial  information in research papers. In BIR 2021: 11th International Workshop on Bibliometric-enhanced",This research is funded by,"Alexandera, D. & Vries, A. P.",2021,Yes
19.1,"Paszke  et  al.,  2019","Paszke  et  al.,  2019","The Flair NLP framework

Flair  is  an  open-sourced  NLP  framework  built  on  PyTorch  (Paszke  et  al.,  2019),  which 
is  an  open-source  machine  learning  library.","Liu, Y., Ott, M., Goyal, N., Du, J., Joshi, M., Chen, D., Levy, O., Lewis, M., Zettlemoyer, L., & Stoy- anov,  V.  (2019).  RoBERTa:  A  robustly  optimized  BERT  pretraining  approach.  arXiv: 1907. 11692 [cs] .",RoBERTa:  A  robustly  optimized  BERT  pretraining  approach,"Liu, Y., Ott, M., Goyal, N., Du, J., Joshi, M., Chen, D., Levy, O., Lewis, M., Zettlemoyer, L., & Stoy- anov,  V.",2019,Yes
20.1,"Akbik  et  al.,  2019,  p.  54","Akbik  et  al.,  2019,  p.  54","“The  core  idea  of  the  framework  is  to  pre-
sent a simple, unified interface for conceptually very different types of word and document 
embeddings”  (Akbik  et  al.,  2019,  p.  54).","N., Antiga, L., Desmaison, A., Köpf, A., Yang, E., DeVito, Z., Raison, M., Tejani, A., Chilamkur- thy,  S.,  Steiner,  B.,  Fang,  L.,  Bai,  J.,  &  Chintala,  S.  (2019).  PyTorch:  An  imperative  style,  high- performance deep learning library. arXiv: 1912. 01703 [cs, stat].","PyTorch:  An  imperative  style,  high- performance deep learning library","N., Antiga, L., Desmaison, A., Köpf, A., Yang, E., DeVito, Z., Raison, M., Tejani, A., Chilamkur- thy,  S.,  Steiner,  B.,  Fang,  L.,  Bai,  J.,  &  Chintala,  S.",2019,Yes
21.1,"Akbik  et  al.,  2018","Akbik  et  al.,  2018","Flair  has  three  default  training  algorithms  for 
NER which were used for the first experiment in the present research: a) NER Model with 
Flair  Embeddings  (later  on  Flair  Embeddings)  (Akbik  et  al.,  2018),  b)  NER  Model  with 
Transformers  (later  on  Transformers)","Akbik, A., Blythe, D., & Vollgraf, R. (2018). Contextual string embeddings for sequence labeling. In 2018,   27th International Conference on Computational Linguistics (pp. 1638–1649).",Contextual string embeddings for sequence labeling,"Akbik, A., Blythe, D., & Vollgraf, R.",2018,Yes
22.1,"Schweter  &  Akbik,  2020","Schweter  &  Akbik,  2020","(Schweter  &  Akbik,  2020),  and  c)  Zero-shot  NER 
with TARS (later on TARS) (Halder et al., 2020) 8.","Schweter, S., & Akbik, A. (2020). FLERT: Document-level features for named entity recognition. ArXiv.   10.48550/arXiv.2011.06993 .",FLERT: Document-level features for named entity recognition,"Schweter, S., & Akbik, A.",2020,Yes
23.1,"Halder et al., 2020","Halder et al., 2020","(Schweter  &  Akbik,  2020),  and  c)  Zero-shot  NER 
with TARS (later on TARS) (Halder et al., 2020) 8.","Schweter, S., & Akbik, A. (2020). FLERT: Document-level features for named entity recognition. ArXiv.   10.48550/arXiv.2011.06993 .",FLERT: Document-level features for named entity recognition,"Schweter, S., & Akbik, A.",2020,Yes
24.1,"Akbik et al., 2018","Akbik et al., 2018","The Flair Embeddings model uses stacked embeddings, i.e., a combination of contex-
tual string embeddings (Akbik et al., 2018) with a static embeddings model.","Akbik, A., Blythe, D., & Vollgraf, R. (2018). Contextual string embeddings for sequence labeling. In 2018,   27th International Conference on Computational Linguistics (pp. 1638–1649).",Contextual string embeddings for sequence labeling,"Akbik, A., Blythe, D., & Vollgraf, R.",2018,Yes
25.1,"Akbik et al., 2019","Akbik et al., 2019","Stacked 
embedding is an important Flair feature, as a combination of different embeddings might 
bring better results than their separate uses (Akbik et al., 2019).","N., Antiga, L., Desmaison, A., Köpf, A., Yang, E., DeVito, Z., Raison, M., Tejani, A., Chilamkur- thy,  S.,  Steiner,  B.,  Fang,  L.,  Bai,  J.,  &  Chintala,  S.  (2019).  PyTorch:  An  imperative  style,  high- performance deep learning library. arXiv: 1912. 01703 [cs, stat].","PyTorch:  An  imperative  style,  high- performance deep learning library","N., Antiga, L., Desmaison, A., Köpf, A., Yang, E., DeVito, Z., Raison, M., Tejani, A., Chilamkur- thy,  S.,  Steiner,  B.,  Fang,  L.,  Bai,  J.,  &  Chintala,  S.",2019,Yes
26.1,"Schweter & Akbik, 
2020","Schweter & Akbik, 
2020","1 3 
Scientometrics 

Table 2   Number of sentences/texts in the training corpora

Corpus No.

Training set (train)

Test set (test)

Validation set (dev)

1

2
3
4

29/27

339/282
784/657
1148/885

10/10

165/150
165/150
165/150

10/10

150/136
150/136
150/136

Total

49/47

654/441
1099/816
1463/1044

Table 3   Number of sentences/texts from each scientific domain in the training corpora

Corpus No.

Oceanography

Economics

Social Sciences

Computer Science

1

2
3

13/13

127/75
175/112

3/3

92/58
128/89

20/20

351/234
590/434

16/14

173/129
333/269

LSTM-CRF with the multilingual XML-RoBERTa transformer model (Schweter & Akbik, 
2020).","Schweter, S., & Akbik, A. (2020). FLERT: Document-level features for named entity recognition. ArXiv.   10.48550/arXiv.2011.06993 .",FLERT: Document-level features for named entity recognition,"Schweter, S., & Akbik, A.",2020,Yes
27.1,"Halder et al., 2020","Halder et al., 2020","(Halder et al., 2020).","Schweter, S., & Akbik, A. (2020). FLERT: Document-level features for named entity recognition. ArXiv.   10.48550/arXiv.2011.06993 .",FLERT: Document-level features for named entity recognition,"Schweter, S., & Akbik, A.",2020,Yes
28.1,"Singh et al., 
2021","Singh et al., 
2021","As WoS contains millions of metadata records (Singh et al., 
2021), the data chosen for the present study was restricted by year and scientific domain 
(for the corpora Nos. 1, 2, and 3) or additionally by the affiliation country (for corpus No.4).","Singh, V. K., Singh, P., Karmakar, M., Leta, J., & Mayr, P. (2021). The journal coverage of web of sci- ence, scopus and dimensions: A comparative analysis. Scientometrics, 126(6), 5113–5142. https:// doi. org/ 10. 1007/ s11192- 021- 03948-5","The journal coverage of web of sci- ence, scopus and dimensions: A comparative analysis","Singh, V. K., Singh, P., Karmakar, M., Leta, J., & Mayr, P.",2021,Yes
29.1,"Diaz-Faes & Bordons, 2017","Diaz-Faes & Bordons, 2017","At  the  same  time, 
information  on  technical  and  instrumental  support  is  more  common  for  the  natural  and 
life sciences domains (Diaz-Faes & Bordons, 2017).","Diaz-Faes, A. A., & Bordons, M. (2017). Making visible the invisible through the analysis of acknowl- edgements  in  the  humanities. Aslib  Journal  of  Information  Management,  69(5),  576–590. https:// doi. org/ 10. 1108/ AJIM- 01- 2017- 0008",Making visible the invisible through the analysis of acknowl- edgements  in  the  humanities,"Diaz-Faes, A. A., & Bordons, M.",2017,Yes
30.1,"Pennington  et  al.,  2014","Pennington  et  al.,  2014","We  applied  GloVe  (Pennington  et  al.,  2014)  as  a  static  word-level 
embedding  model.","Pennington, J., Socher, R., & Manning, C. D. (2014). GloVe: Global Vectors for Word Representation.",GloVe: Global Vectors for Word Representation,"Pennington, J., Socher, R., & Manning, C. D.",2014,Yes
31.1,"Liu et al., 2019","Liu et al., 2019","For Transformers, training was initiated with the RoBERTa model (Liu et al., 2019).","Liu, Y., Ott, M., Goyal, N., Du, J., Joshi, M., Chen, D., Levy, O., Lewis, M., Zettlemoyer, L., & Stoy- anov,  V.  (2019).  RoBERTa:  A  robustly  optimized  BERT  pretraining  approach.  arXiv: 1907. 11692 [cs] .",RoBERTa:  A  robustly  optimized  BERT  pretraining  approach,"Liu, Y., Ott, M., Goyal, N., Du, J., Joshi, M., Chen, D., Levy, O., Lewis, M., Zettlemoyer, L., & Stoy- anov,  V.",2019,Yes
32.1,"Schweter 
& Akbik, 2020","Schweter 
& Akbik, 2020","We used a standard approach, where only a linear classifier layer was added on the 
top of the transformer, as adding the additional CRF decoder between the transformer and 
linear classifier did not increase accuracy compared with this standard approach (Schweter 
& Akbik, 2020).","Schweter, S., & Akbik, A. (2020). FLERT: Document-level features for named entity recognition. ArXiv.   10.48550/arXiv.2011.06993 .",FLERT: Document-level features for named entity recognition,"Schweter, S., & Akbik, A.",2020,Yes
33.1,"Kingma  &  Ba, 
2014","Kingma  &  Ba, 
2014","The training was initi-
ated  with  a  small  learning  rate  using  the  Adam  Optimisation  Algorithm  (Kingma  &  Ba, 
2014).","Kingma,  D.  P.,  &  Ba,  J.  (2014).  Adam:  A  method  for  stochastic  optimization.  10.48550/",Adam:  A  method  for  stochastic  optimization,"Kingma,  D.  P.,  &  Ba,  J.",2014,Yes
34.1,"Halder et al., 2020","Halder et al., 2020","The training for the few-shot approach was initiated 
with the TARS NER model (Halder et al., 2020).","Schweter, S., & Akbik, A. (2020). FLERT: Document-level features for named entity recognition. ArXiv.   10.48550/arXiv.2011.06993 .",FLERT: Document-level features for named entity recognition,"Schweter, S., & Akbik, A.",2020,Yes
35.1,"Schweter  &  Akbik,  2020","Schweter  &  Akbik,  2020","On the one hand, Flair developers claimed Transformers to be the most effi-
cient  algorithm  (Schweter  &  Akbik,  2020).","Schweter, S., & Akbik, A. (2020). FLERT: Document-level features for named entity recognition. ArXiv.   10.48550/arXiv.2011.06993 .",FLERT: Document-level features for named entity recognition,"Schweter, S., & Akbik, A.",2020,Yes
36.1,"Akbik  et  al.,  2019","Akbik  et  al.,  2019","On  the  other,  the  stacked  embeddings  are 
an important feature of the Flair tool, as a combination of different embeddings might 
bring  better  results  than  their  separate  uses  (Akbik  et  al.,  2019).","N., Antiga, L., Desmaison, A., Köpf, A., Yang, E., DeVito, Z., Raison, M., Tejani, A., Chilamkur- thy,  S.,  Steiner,  B.,  Fang,  L.,  Bai,  J.,  &  Chintala,  S.  (2019).  PyTorch:  An  imperative  style,  high- performance deep learning library. arXiv: 1912. 01703 [cs, stat].","PyTorch:  An  imperative  style,  high- performance deep learning library","N., Antiga, L., Desmaison, A., Köpf, A., Yang, E., DeVito, Z., Raison, M., Tejani, A., Chilamkur- thy,  S.,  Steiner,  B.,  Fang,  L.,  Bai,  J.,  &  Chintala,  S.",2019,Yes
37.1,"Chelba et al., 2013","Chelba et al., 2013","Thus, Flair Embeddings were 
trained on the 1-billion words English corpus (Chelba et al., 2013).","Chelba,  C.,  T.  Mikolov,  M.  Schuster,  Q.  Ge,  T.  Brants,  P.  Koehn,  &  Robinson,  T.  (2013).  One  Bil- lion  Word  Benchmark  for  Measuring  Progress  in  Statistical  Language  Modeling.  10.48550/",One  Bil- lion  Word  Benchmark  for  Measuring  Progress  in  Statistical  Language  Modeling,"Chelba,  C.,  T.  Mikolov,  M.  Schuster,  Q.  Ge,  T.  Brants,  P.  Koehn,  &  Robinson,  T.",2013,Yes
38.1,"Shen et al., 2022; Beltagy et al.., 2019","Shen et al., 2022","Previous  works  showed  improvements  in  downstream  tasks  using  embedding  models 
fine-tuned for the domain used (Shen et al., 2022; Beltagy et al.., 2019).","Shen,  S.,  Liu,  J.,  Lin,  L.,  Huang,  Y.,  Zhang,  L.,  Liu,  C.,  Feng,  Y.,  &  Wang,  D.  (2022).  SsciBERT:  A  pre-trained  language  model  for  social  science  texts.  Scientometrics.  https:// doi. org/ 10. 1007/ s11192- 022- 04602-4",SsciBERT:  A  pre-trained  language  model  for  social  science  texts,"Shen,  S.,  Liu,  J.,  Lin,  L.,  Huang,  Y.,  Zhang,  L.,  Liu,  C.,  Feng,  Y.,  &  Wang,  D.",2022,Yes
38.2,"Shen et al., 2022; Beltagy et al.., 2019","Beltagy et al.., 2019","Previous  works  showed  improvements  in  downstream  tasks  using  embedding  models 
fine-tuned for the domain used (Shen et al., 2022; Beltagy et al.., 2019).","Beltagy,  I.,  Lo,  K.,  &  Cohan,  A.  (2019).  SciBERT:  A  pretrained  language  model  for  scientific  text.",SciBERT:  A  pretrained  language  model  for  scientific  text,"Beltagy,  I.,  Lo,  K.,  &  Cohan,  A.",2019,Yes
39.1,"Smirnova & Mayr, 2023","Smirnova & Mayr, 2023","Moreover,  further  analysis  of  acknowledged  entities  showed  that  the  miscellaneous  cate-
gory contained very inhomogeneous and partly irrelevant data, making the analysis more 
complicated (Smirnova & Mayr, 2023).","Smirnova,  N.,  &  Mayr,  P.  (2023).  A  comprehensive  analysis  of  acknowledgement  texts  in  web  of  sci- ence: A case study on four scientific domains. Scientometrics, 1(128), 709–734. https:// doi. org/ 10. 1007/ s11192- 022- 04554-9",A  comprehensive  analysis  of  acknowledgement  texts  in  web  of  sci- ence: A case study on four scientific domains,"Smirnova,  N.,  &  Mayr,  P.",2023,Yes
40.1,"Smirnova  & 
Mayr, 2023","Smirnova  & 
Mayr, 2023","Analysis of the extracted entities showed that many 
entities  were  extracted  correctly,  but  were  assigned  to  the  wrong  category  (Smirnova  & 
Mayr, 2023).","Smirnova,  N.,  &  Mayr,  P.  (2023).  A  comprehensive  analysis  of  acknowledgement  texts  in  web  of  sci- ence: A case study on four scientific domains. Scientometrics, 1(128), 709–734. https:// doi. org/ 10. 1007/ s11192- 022- 04554-9",A  comprehensive  analysis  of  acknowledgement  texts  in  web  of  sci- ence: A case study on four scientific domains,"Smirnova,  N.,  &  Mayr,  P.",2023,Yes
41.1,"Smirnova & 
Mayr, 2022","Smirnova & 
Mayr, 2022","The present paper is an extended version of the paper “Evaluation of Embedding Models for 
Automatic Extraction and Classification of Acknowledged Entities in Scientific Documents” (Smirnova & 
Mayr, 2022) presented at the 3rd Workshop on Extraction and Evaluation of Knowledge Entities from Sci-
entific Documents (EEKE2022).","Smirnova, N., & Mayr, P. (2022). Evaluation of embedding models for automatic extraction and classifi- cation of acknowledged entities in scientific documents. In 3rd Workshop on Extraction and Evalu- ation of Knowledge Entities from Scientific Documents 2022 (EEKE 2022) (pp. 48–55). CEUR-WS. org.",Evaluation of embedding models for automatic extraction and classifi- cation of acknowledged entities in scientific documents,"Smirnova, N., & Mayr, P.",2022,Yes
